<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>2019给自己的年终总结</title>
    <url>/2019/12/31/2019%E7%BB%99%E8%87%AA%E5%B7%B1%E7%9A%84%E5%B9%B4%E7%BB%88%E6%80%BB%E7%BB%93/</url>
    <content><![CDATA[<h2 id="开头"><a href="#开头" class="headerlink" title="开头:"></a>开头:</h2><p>新的一年新的气象，我看各个博主都已经开始给自己立了一个新年的总结，下午前脚把代码Push上，我就过来给自己一个总结，毕竟觉得自己是挺重要的一年！</p>
<p><img  
                     lazyload
                     alt="image"
                     data-src="https://i.loli.net/2020/01/07/enWjrY9S1hqv3yZ.png"
                     
                ></p>
<p>因为自己是做技术的，先总结一下自己的技术:</p>
<h2 id="技术"><a href="#技术" class="headerlink" title="技术:"></a>技术:</h2><p>今年是个提升自己的一年，为什么这么说呢？ 自己的编码水平得到了突飞猛进的进展(目前自认为)。因为之前自己的水平回忆起来真的是不堪回首。</p>
<p>新的一年，掌握了新的微服务框架技术、Docker容器化技术、以及Java相关的常用化组件等等…..当然2020年我还会继续向这种高用户量的需求解决框架延申，为自己扩展提升更好的技能。</p>
<h2 id="旅游"><a href="#旅游" class="headerlink" title="旅游:"></a>旅游:</h2><p>今年的旅游收获了很多的好心情，并且发现去一个很美的地方可以让人快速的修复自己疲惫的心灵，也跟自己的好哥们第一次去人生中的海边，旅游没得说，之后有机会我就一定会选择去旅游，也还有自己在北京觉得很好看的地方。</p>
<h3 id="日出"><a href="#日出" class="headerlink" title="日出"></a>日出</h3><p><img  
                     lazyload
                     alt="image"
                     data-src="https://i.loli.net/2020/01/07/jcqbF5sQ9fAelRK.jpg"
                     
                ></p>
<p><img  
                     lazyload
                     alt="image"
                     data-src="https://i.loli.net/2020/01/07/jqrcFGks3h8libd.jpg"
                     
                ></p>
<h3 id="海边"><a href="#海边" class="headerlink" title="海边:"></a>海边:</h3><p><img  
                     lazyload
                     alt="image"
                     data-src="https://i.loli.net/2020/01/07/obiJYVqTuKL9NcF.jpg"
                     
                ></p>
<h3 id="海洋馆"><a href="#海洋馆" class="headerlink" title="海洋馆:"></a>海洋馆:</h3><p><img  
                     lazyload
                     alt="image"
                     data-src="https://i.loli.net/2020/01/07/Xxd7Nib1eCAYVhm.jpg"
                     
                ></p>
<h3 id="冰面"><a href="#冰面" class="headerlink" title="冰面:"></a>冰面:</h3><p><img  
                     lazyload
                     alt="image"
                     data-src="https://i.loli.net/2020/01/07/GVxU3nbHXwDtuNQ.jpg"
                     
                ></p>
<h3 id="在北京的记忆"><a href="#在北京的记忆" class="headerlink" title="在北京的记忆:"></a>在北京的记忆:</h3><p><img  
                     lazyload
                     alt="image"
                     data-src="https://i.loli.net/2020/01/07/dxbUINkXyFBYeGA.jpg"
                     
                ></p>
<p><img  
                     lazyload
                     alt="image"
                     data-src="https://i.loli.net/2020/01/07/dzh1gmHbosr8JGe.jpg"
                     
                ></p>
<p><img  
                     lazyload
                     alt="image"
                     data-src="https://i.loli.net/2020/01/07/p1m3I4MtHjaiqTr.jpg"
                     
                ></p>
<h2 id="工作"><a href="#工作" class="headerlink" title="工作:"></a>工作:</h2><p>今年年底入职北京的一家公司担任  Java开发工程师  一职 ，目前的项目为: “金库管理平台”，当然，我只是一个这个面向B端产品的一个小蚂蚁，新的一年我也会更加努力的去做好我的本职工作，努力提升自己。好好生活，对自己要好一点！家人都不在身边，只能自己照顾好自己，嘻嘻~</p>
<h2 id="博客"><a href="#博客" class="headerlink" title="博客:"></a>博客:</h2><p>在2019年，自己没有抽出来时间管理自己的发霉的小窝。但是我一直有关注。我、以及我的朋友们的博客似乎都缺少了时间来管理自己的博客，因为回想起来从17年到现在了，大家有的站点还在坚持更新记录。有的已经遗憾的Get不到了，我也好几次没有打理出来自己的博客，不过我还是坚持过来了！</p>
<p>不管怎么样希望看见这篇总结的朋友 新的一年前程似锦。</p>
<p>往前的目标我就更清楚了。新的一年，我要抽出来更多的时间来管理自己的博客，记录自己的生活。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结:"></a>总结:</h2><p>扯了这么多，把自己的2019年的flag拿出来，对比一下。</p>
<p>1.在北京实习找到一份稳定的饭碗。  √</p>
<p>2.去一次旅游(见一个人) 不知道能不能   ×   我想之后可能也不会了。</p>
<p>3.希望在年底学会开车   嗯，这个已经在练习考科一做题了，年假回家学习开车。</p>
<p>新的一年对自己说的话:</p>
<p>2020,张帅轲 希望你好好努力，要对自己的技术要求更严格，对自己的提升永远不要放下。不辜负自己、朋友、家人才是最重要的，加油。</p>
]]></content>
      <tags>
        <tag>总结</tag>
      </tags>
  </entry>
  <entry>
    <title>video玩出新花样当background</title>
    <url>/2018/05/20/video/</url>
    <content><![CDATA[<p>hi,好久不见啊。转眼间端午节了，不知道你们又在干嘛呢？别的不扯了，端午节快乐啊哈~</p>
<p>因为前几天我们要进行网页设计大赛，所以我们小组又焦头烂额的坐在了一起：“又做东西啊，烦死了”！最终我们还是做出来了。也得了个第一名，虽然不怎么好。但也是对自己努力的一个肯定。</p>
<p>学习中遇见了一些问题就不说了，我们做的页面是支付宝全站，但是支付宝个人中心有一个拿video当做视频背景的元素，我们一直没搞懂。但是恍然大悟，我们可以使用<strong>z-index</strong>属性来定义啊。好那么我们详细欣赏下面的教程！</p>
<p>下面先给大家截图一下这个效果吧，大神勿喷~ 但是截图的又不能动~~<br><img  
                     lazyload
                     alt="image"
                     data-src="https://i.loli.net/2018/06/16/5b24585f4e279.png"
                      alt="支付宝video首页"
                ></p>
<p>多了话不多说我们先来分析一波，首先我们这个东西用视频当做背景，所以背景一定在下面的，所以设置他的层级代码肯定为负的最多的，因为上面要放内容。那么我们既然弄肯定要全屏还有把他固定在哪里，即使我们不设置数值。然后设置他的显示亮度。多了不说了css代码上了。</p>
<p><img  
                     lazyload
                     alt="image"
                     data-src="https://i.loli.net/2018/06/16/5b2457feccb34.png"
                      alt="css代码样式"
                ><br>那么看到这里就有疑问了，有人问 <strong>-webkit-filter:grayscale(100%)</strong> 这段代码是干嘛的，显示的亮度。但是需要支付浏览器，webkit是兼容谷歌的，如果展示在用户面前需要兼容多个浏览器，具体的自行百度下。</p>
<p>好那么我们css设置完成了，好我们展示下我们html的代码吧。<br><img  
                     lazyload
                     alt="image"
                     data-src="https://i.loli.net/2018/06/16/5b245a9666c58.png"
                      alt="中心展示代码"
                ><br>这个代码其实就是正常的插入一段视频。无需多的理解。</p>
<p>好一个视频已经展现在我们的面前，总是感觉视频的速度可能播放太快或者太慢没有视觉感觉。好我们定义一下他的视频背景，首先这个 id&#x3D;v1 v1是自己取得名字，这个根据开发者自己来定。<strong>其中的0.5自行改数值。</strong></p>
<p><img  
                     lazyload
                     alt="image"
                     data-src="https://i.loli.net/2018/06/16/5b245b49bda2c.png"
                      alt="js代码"
                ></p>
<p>就这么简单我们的一个页面已经制作完成啦。现在我们看下效果吧！有什么不懂得可以QQ问我哦~</p>
]]></content>
      <tags>
        <tag>技术</tag>
      </tags>
  </entry>
  <entry>
    <title>Kafka学习笔记</title>
    <url>/2022/12/25/Kafka%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<h1 id="Kafka基本的概念"><a href="#Kafka基本的概念" class="headerlink" title="Kafka基本的概念"></a>Kafka基本的概念</h1><p>Kafka是最初由Linkedin公司开发，是一个分布式、分区的、多副本的、多订阅者，**基于zookeeper协调的分布式日志系统(也可以当做MQ系统)**，常见可以用于web&#x2F;nginx日志、访问日志，消息服务等等，Linkedin于2010年贡献给了Apache基金会并成为顶级开源项目。<br><img  
                     lazyload
                     alt="image"
                     data-src="https://s2.loli.net/2022/12/25/uYclj9Fd5HU7v8N.png"
                      alt="image.png"
                ></p>
<h2 id="Kafka部分名词解释如下"><a href="#Kafka部分名词解释如下" class="headerlink" title="Kafka部分名词解释如下"></a>Kafka部分名词解释如下</h2><ul>
<li>Broker：消息中间件处理结点，一个Kafka节点就是一个broker，多个broker可以组成一个Kafka集群。</li>
<li>Topic：一类消息，例如page view日志、click、短信、日志等都可以以topic的形式存在，Kafka集群能够同时负责多个topic的分发。</li>
<li>Partition：topic物理上的分组，一个topic可以分为多个partition，每个partition是一个有序的队列。相当于分区</li>
<li>Segment：partition物理上由多个segment组成</li>
<li>offset：每个partition都由一系列有序的、不可变的消息组成，这些消息被连续的追加到partition中。partition中的每个消息都有一个连续的序列号叫做offset,用于partition唯一标识一条消息.</li>
<li>Producer：消息的生产者，负责向Broker中投递消息</li>
<li>Consumer：消息的消费者，负责从Broker中拉取消息</li>
<li>Consumer Group：消费者组，在同一个消费者组中是不能够消费同一个分区中的消息的。在多个不同的消费组中，多个不同的消费者可以消费同一条消息</li>
</ul>
<p><img  
                     lazyload
                     alt="image"
                     data-src="https://s2.loli.net/2022/12/25/amST2Jd53PFiXYx.png"
                      alt="image.png"
                ></p>
<h2 id="Kafka消息队列模型"><a href="#Kafka消息队列模型" class="headerlink" title="Kafka消息队列模型"></a>Kafka消息队列模型</h2><p>kafka的消息队列一般分为两种模式：点对点和订阅模式</p>
<h3 id="点对点模式"><a href="#点对点模式" class="headerlink" title="点对点模式"></a>点对点模式</h3><p>Kafka 是支持消费者群组的，也就是说 Kafka 中会有一个或者多个消费者，如果一个生产者生产的消息由一个消费者进行消费的话，那么这种模式就是点对点模式<br><img  
                     lazyload
                     alt="image"
                     data-src="https://s2.loli.net/2022/12/25/tIs7KyxDedwA1VM.png"
                      alt="image.png"
                ></p>
<h3 id="发布订阅模式"><a href="#发布订阅模式" class="headerlink" title="发布订阅模式"></a>发布订阅模式</h3><p>如果一个生产者或者多个生产者产生的消息能够被多个消费者同时消费的情况，这样的消息队列成为发布订阅模式的消息队列<br><img  
                     lazyload
                     alt="image"
                     data-src="https://s2.loli.net/2022/12/25/TqlW5aN6siXt7nz.png"
                      alt="image.png"
                ></p>
<h2 id="Kafka有哪些特性致使它性能这么高？"><a href="#Kafka有哪些特性致使它性能这么高？" class="headerlink" title="Kafka有哪些特性致使它性能这么高？"></a>Kafka有哪些特性致使它性能这么高？</h2><ul>
<li>顺序读写</li>
<li>零拷贝</li>
<li>消息压缩</li>
<li>分批发送</li>
</ul>
<h2 id="Kafka的设计原理"><a href="#Kafka的设计原理" class="headerlink" title="Kafka的设计原理"></a>Kafka的设计原理</h2><ol>
<li>高吞吐、低延迟：kakfa 最大的特点就是收发消息非常快，kafka 每秒可以处理几十万条消息，它的最低延迟只有几毫秒；</li>
<li>高伸缩性：每个主题(topic) 包含多个分区(partition)，主题中的分区可以分布在不同的主机(broker)中；</li>
<li>持久性、可靠性：Kafka 能够允许数据的持久化存储，消息被持久化到磁盘，并支持数据备份防止数据丢失，Kafka 底层的数据存储是基于 Zookeeper 存储的，Zookeeper 我们知道它的数据能够持久存储；</li>
<li>容错性：允许集群中的节点失败，某个节点宕机，Kafka 集群能够正常工作；</li>
<li>高并发：支持数千个客户端同时读写。</li>
</ol>
<h1 id="kafka的设计原理"><a href="#kafka的设计原理" class="headerlink" title="kafka的设计原理"></a>kafka的设计原理</h1><h2 id="kafka文件存储原理"><a href="#kafka文件存储原理" class="headerlink" title="kafka文件存储原理"></a>kafka文件存储原理</h2><ol>
<li>Kafka实际上就是日志消息存储系统， 根据offset获取对应的消息，消费者获取到消息之后</li>
</ol>
<p>该消息不会立即从mq中移除。</p>
<ol start="2">
<li>将topic分成多个不同的分区、每个分区中拆分成多个不同的segment文件存储日志。</li>
<li>每个segment文件会有<ul>
<li>.index 消息偏移量索引文件</li>
<li>.log文件 消息物理存放的位置</li>
</ul>
</li>
</ol>
<p>在默认的情况下，每个segment文件容量最大是为500mb，如果超过500mb的情况下依次内推，产生一个新的segment文件</p>
<h3 id="topic中partition存储分布"><a href="#topic中partition存储分布" class="headerlink" title="topic中partition存储分布"></a>topic中partition存储分布</h3><p>假设一个kafka集群中只有一个broker，<code>opt/keshao/message-data</code>为数据文件存储目录，在Kafka broker中的server.properties文件配置（参数：<code>log.dirs</code>），例如创建2个topic名称分别为report_pushlaunch_info,partitions数量都为<code>partitions=4 </code></p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line">|--report_push<span class="number">-0</span></span><br><span class="line">|--report_push<span class="number">-1</span></span><br><span class="line">|--report_push<span class="number">-2</span></span><br><span class="line">|--report_push<span class="number">-3</span></span><br><span class="line">|--launch_info<span class="number">-0</span></span><br><span class="line">|--launch_info<span class="number">-1</span></span><br><span class="line">|--launch_info<span class="number">-2</span></span><br><span class="line">|--launch_info<span class="number">-3</span></span><br></pre></td></tr></table></figure>
<p>在Kafka文件存储中，同一个topic下有多个不同partition，每个partition为一个目录，partiton命名规则为topic名称+有序序号，第一个partiton序号从0开始，序号最大值为partitions数量减1。 如果是多broker分布情况，请参考<a class="link"   href="http://blog.csdn.net/lizhitao/article/details/41778193" >kafka集群partition分布原理分析<i class="fas fa-external-link-alt"></i></a></p>
<h3 id="partition中文件存储方式"><a href="#partition中文件存储方式" class="headerlink" title="partition中文件存储方式"></a>partition中文件存储方式</h3><ul>
<li>每个partiton中相当于一个巨型文件被平均分配到多个大小相等segment（段）数据中。但每个段segment file消息数量不一定相等，这种特性方便old segment被快速检索删除</li>
<li>每个partiton只需要顺序读写就可以了，segment文件生命周期由服务端配置参数决定。</li>
<li>这样做的好处就是能快速删除无用文件，有效提高磁盘利用率。</li>
</ul>
<p><img  
                     lazyload
                     alt="image"
                     data-src="https://s2.loli.net/2022/12/25/wPCEouTMVZAlvLa.png"
                      alt="image.png"
                ></p>
<h3 id="partiton中segment文件存储结构"><a href="#partiton中segment文件存储结构" class="headerlink" title="partiton中segment文件存储结构"></a>partiton中segment文件存储结构</h3><ul>
<li>segment file由2大部分组成，分别index file和data file，两个文件一一对应，成对出现。后缀<code>.index</code>和<code>.log</code>分别表示为segment索引文件、数据文件；</li>
<li>segment文件命名规则：partiton全局的第一个segment0开始，后续每个setment文件名为上一个segment文件最后一条消息的offset值。数值最大为64位long大小，19位数字字符长度，没有数字用0填充；</li>
</ul>
<p>文件的是Kafka broker中做的一个实验，创建一个topicXXX包含1 partiton，设置每个segment大小为500MB，并启动producer向Kafka broker写入大量数据<br><img  
                     lazyload
                     alt="image"
                     data-src="https://s2.loli.net/2022/12/25/wRC7YxMThmutsVF.png"
                      alt="image.png"
                ><br>segment file中，index与file的物理关系如下：<br><img  
                     lazyload
                     alt="image"
                     data-src="https://s2.loli.net/2022/12/25/vqM6nWLVGPlaSkF.png"
                      alt="image.png"
                ><br>查找顺序：<br>查找offset&#x3D;6的消息的流程如下</p>
<ol>
<li>二分查找算法：查找到该分区中所有的Segment文件 list排序  每个Segment文件都是有一个命名规范，offset&#x3D;7在我们的Segment文件中，此处定位到index文件</li>
<li>先访问该index文件，根据offset值查询到物理存放位置，Offset&#x3D;7&gt;6&lt;9 所以定位到offset&#x3D;6 获取到物理存放位置1407</li>
<li>根据该物理存放位置9807 去对应的log文件查找消息，依次向下查找+1次 获取到offset&#x3D;7的消息。</li>
</ol>
<p>为什么kafka中的 索引文件没有对每个消息建立索引呢？</p>
<ol>
<li>目的是为了节约我们空间的资源</li>
<li>稀疏索引算法+二分查找算法，定位到位置，在根据顺序遍历查找。<br>如果该offset消息 没有对应的索引的情况下，时间复杂度是为多少：（ON）<br>如果该offset消息 有对应的索引的情况下，时间复杂度是为多少：（O1）</li>
</ol>
<h3 id="message的存储方式"><a href="#message的存储方式" class="headerlink" title="message的存储方式"></a>message的存储方式</h3><p>表格中列出了message的物理结构：</p>
<table>
<thead>
<tr>
<th>关键字</th>
<th>解释说明</th>
</tr>
</thead>
<tbody><tr>
<td>8 byte offset</td>
<td>在parition(分区)内的每条消息都有一个有序的id号，这个id号被称为偏移(offset),它可以唯一确定每条消息在parition(分区)内的位置。即offset表示partiion的第多少message</td>
</tr>
<tr>
<td>4 byte message size</td>
<td>message大小</td>
</tr>
<tr>
<td>4 byte CRC32</td>
<td>用crc32校验message</td>
</tr>
<tr>
<td>1 byte “magic”</td>
<td>表示本次发布Kafka服务程序协议版本号</td>
</tr>
<tr>
<td>1 byte “attributes”</td>
<td>表示为独立版本、或标识压缩类型、或编码类型。</td>
</tr>
<tr>
<td>4 byte key length</td>
<td>表示key的长度,当key为-1时，K byte key字段不填</td>
</tr>
<tr>
<td>K byte key</td>
<td>可选</td>
</tr>
<tr>
<td>value bytes payload</td>
<td>表示实际消息数据。</td>
</tr>
</tbody></table>
<h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><p>Kafka运行时很少有大量读磁盘的操作，主要是定期批量写磁盘操作，因此操作磁盘很高效。这跟Kafka文件存储中读写message的设计是息息相关的。Kafka中读写message有如下特点:<br>写message</p>
<ul>
<li>消息从java堆转入page cache(即物理内存)。</li>
<li>由异步线程刷盘,消息从page cache刷入磁盘。</li>
</ul>
<p>读message</p>
<ul>
<li>消息直接从page cache转入socket发送出去。</li>
<li>当从page cache没有找到相应数据时，此时会产生磁盘IO,从磁 盘Load消息到page cache,然后直接从socket发出去</li>
</ul>
<p>Kafka高效文件存储设计特点</p>
<ol>
<li>Kafka把topic中一个parition大文件分成多个小文件段，通过多个小文件段，就容易定期清除或删除已经消费完文件，减少磁盘占用。</li>
<li>通过索引信息可以快速定位message和确定response的最大大小。</li>
<li>通过index元数据全部映射到memory，可以避免segment file的IO磁盘操作。</li>
<li>通过索引文件稀疏存储，可以大幅降低index文件元数据占用空间大小。</li>
</ol>
<p>无论消息是否被消费，kafka都会保存所有的消息，旧消息删除策略<br>1、 基于时间，默认配置是168小时（7天）。<br>2、 基于大小，默认配置是1073741824。</p>
<h2 id="Kafka如何保证生产消息可靠性"><a href="#Kafka如何保证生产消息可靠性" class="headerlink" title="Kafka如何保证生产消息可靠性"></a>Kafka如何保证生产消息可靠性</h2><h3 id="副本机制"><a href="#副本机制" class="headerlink" title="副本机制"></a>副本机制</h3><p>副本机制（Replication）：也可以称之为备份机制，通常是指分布式系统在多台互联网的机器上保存相同的数据拷贝，副本机制有什么好处？</p>
<ul>
<li>提供数据冗余：即使系统部分组件失效，系统依然能够继续运转，因而增加了整体可用性以及数据持久性</li>
<li>提供高伸缩性：支持横向扩展，能够通过添加机器的方式来提升读的性能，进而提高读操作吞吐量</li>
<li>改善数据局部性：允许将数据放入与用户地理位置相近的地方，从而降低系统延时</li>
</ul>
<p>kafka是有主题概念的，而每一个主题又进一步划分成若干个分区。副本的概念实际上是在分区层级下定义的，每个分区配置有多若干个副本。<br>所谓的副本，本质上就是一个只能追加写消息的提交日志，根据kafka副本机制的定义，同一个分区下的所有副本保存有相同的消息序列，这些副本分散的保存在不同的Broker上，从而能够对抗部分Broker宕机带来的数据不可用。<br><img  
                     lazyload
                     alt="image"
                     data-src="https://s2.loli.net/2022/12/25/TF1geoplAOyHvVj.png"
                      alt="image.png"
                ></p>
<h3 id="kafka有了副本机制是否会发生数据丢失？"><a href="#kafka有了副本机制是否会发生数据丢失？" class="headerlink" title="kafka有了副本机制是否会发生数据丢失？"></a>kafka有了副本机制是否会发生数据丢失？</h3><p>会。写入数据都是往某个Partition的Leader写入的，然后那个Partition的Follower会从Leader同步数据，但是这个同步过程是异步的。也就是说如果此时1条数据刚写入Leader Partition1，还没来得及同步给Follower，Leader Partiton1所在机器突然就宕机了的话，此时就会选举Partition1的Follower作为新的Leader对外提供服务，然后用户就读不到刚才写入的那条数据了。因为Partition0的Follower上是没有同步到最新的一条数据的，这个时候就会造成数据丢失的问题。</p>
<h3 id="Kafka的ISR机制"><a href="#Kafka的ISR机制" class="headerlink" title="Kafka的ISR机制"></a>Kafka的ISR机制</h3><blockquote>
<p><strong>此处的Leader是Partition的Leader，而不是Broker的Leader</strong></p>
</blockquote>
<p>这个机制简单来说，就是会自动给每个Partition维护一个ISR列表，这个列表里一定会有Leader，然后还会包含跟Leader保持同步的Follower。也就是说，只要Leader的某个Follower一直跟他保持数据同步，那么就会存在于ISR列表里。<br>但是如果Follower因为自身发生一些问题，导致不能及时的从Leader同步数据过去，那么这个Follower就会被认为是“out-of-sync”，从ISR列表里移除。</p>
<h4 id="怎么保证Kafka写入的数据不丢失？"><a href="#怎么保证Kafka写入的数据不丢失？" class="headerlink" title="怎么保证Kafka写入的数据不丢失？"></a>怎么保证Kafka写入的数据不丢失？</h4><ol>
<li>每个Partition都至少得有1个Follower在ISR列表里，跟上了Leader的数据同步</li>
<li>每次写入数据的时候，都要求至少写入Partition Leader成功，同时还有至少一个ISR里的Follower也写入成功，才算这个写入是成功了</li>
<li>如果不满足上述两个条件，那就一直写入失败，让生产系统不停的尝试重试，直到满足上述两个条件，然后才能认为写入成功</li>
<li>这个时候万一leader宕机，就可以切换到那个follower上去，那么Follower上是有刚写入的数据的，此时数据就不会丢失了。</li>
</ol>
<p>关于第二点就需要去配置相应ack参数，才能保证写入Kafka的数据不会丢失。</p>
<h3 id="Kafka的ack消息模式"><a href="#Kafka的ack消息模式" class="headerlink" title="Kafka的ack消息模式"></a>Kafka的ack消息模式</h3><p>acks参数，是在Kafka Producer，也就是生产者里设置的。<br>这个参数实际上有三种常见的值可以设置，分别是：0、1 和 all。</p>
<ul>
<li>0： Producer 不等待 Broker 的 ACK，这提供了最低延迟，Broker 一收到数据还没有写入磁盘就已经返回，当 Broker 故障时有可能丢失数据。</li>
<li>1:   Producer 等待 Broker 的 ACK，Partition 的 Leader 落盘成功后返回 ACK，如果在 Follower 同步成功之前 Leader 故障，那么将会丢失数据。</li>
<li>-1 （all）： Producer 等待 Broker 的 ACK，Partition 的 Leader 和 Follower 全部落盘成功后才返回 ACK。但是在 Broker 发送 ACK 时，Leader 发生故障，则会造成数据重复。</li>
</ul>
<h3 id="副本选举实现原理"><a href="#副本选举实现原理" class="headerlink" title="副本选举实现原理"></a>副本选举实现原理</h3><p>当Leader副本宕机之后，会从ISR同步副本列表中剔除，然后取出剩下的ISR列表中第一个为Lader副本，显然还有可能数据没有及时同步完成，当选择为Leader副本之后，数据还会可能存在丢失的情况。<br><img  
                     lazyload
                     alt="image"
                     data-src="https://s2.loli.net/2022/12/25/TjdnofsSGYVCuHF.png"
                      alt="image.png"
                ></p>
<h3 id="副本故障处理机制"><a href="#副本故障处理机制" class="headerlink" title="副本故障处理机制"></a>副本故障处理机制</h3><ul>
<li>LEO:每个副本数据最后一个的offset或者最大的offset值。</li>
<li>HW 消费者能够看见到的最大offset值。</li>
</ul>
<p><img  
                     lazyload
                     alt="image"
                     data-src="https://s2.loli.net/2022/12/25/s9dfBZwzlkT25yK.png"
                      alt="image.png"
                ></p>
<h4 id="Follower节点发生故障原理"><a href="#Follower节点发生故障原理" class="headerlink" title="Follower节点发生故障原理"></a>Follower节点发生故障原理</h4><p>当我们follower2节点如果宕机之后，就会从ISR列表中剔除，有突然恢复了，则开始同步Leader 节点的数据。<br>如何同步：如果follower 的leo不等于Leader 节点的leo，则开始截取高于当前hw位置的log，从该hw位置开始同步Leader 节点数据，如果该follower的leo大于该分区的hw，则从新加入isr列表中。<br><strong>Kafka实现集群，保证每个副本的数据一致性问题，但是不能保证消息不会丢失</strong><br>:::warning<br>发生该问题如何解决？<br>生产者投递消息采用日志形式记录下来，如果消费者消费成功之后，在可以将该消息给删除。<br>:::</p>
<h4 id="Leader节点发生故障原理"><a href="#Leader节点发生故障原理" class="headerlink" title="Leader节点发生故障原理"></a>Leader节点发生故障原理</h4><p>如果Leader节点宕机之后，会从新在剩余的isr列表中，选举一个新的Leader节点。为了保证每个节点中副本一致性的问题，会将高与hw位置的log给截取掉。<br>所以我们kafka为了严格意义上，保证每个节点副本数据一致性问题，但是不能保证数据不丢失。<br>概率：—-非常低。<br>解决办法：<br>生产者投递消息的时候采用日志记录的方式，如果发生Leader变为follower 部分的消息被丢失的情况下，我们可以使用生产投递日志实现补偿。</p>
<h2 id="Kafka选举原理控制器原理"><a href="#Kafka选举原理控制器原理" class="headerlink" title="Kafka选举原理控制器原理"></a>Kafka选举原理控制器原理</h2><p><strong>控制器组件（Controller），是 Apache Kafka 的核心组件。它的主要作用是在 Apache ZooKeeper 的帮助下管理和协调整个 Kafka 集群</strong>。在分布式系统中，通常需要有一个协调者，该协调者会在分布式系统发生异常时发挥特殊的作用。在Kafka中该协调者称之为控制器(Controller),其实该控制器并没有什么特殊之处，它本身也是一个普通的Broker，只不过需要负责一些额外的工作(追踪集群中的其他Broker，并在合适的时候处理新加入的和失败的Broker节点、Rebalance分区、分配新的leader分区等)。值得注意的是：<strong>Kafka集群中始终只有一个Controller Broker。</strong></p>
<h3 id="Controller-Broker是如何被选出来的"><a href="#Controller-Broker是如何被选出来的" class="headerlink" title="Controller Broker是如何被选出来的"></a>Controller Broker是如何被选出来的</h3><p>Broker 在启动时，会尝试去 ZooKeeper 中创建 &#x2F;controller 节点。Kafka 当前选举控制器的规则是：<strong>第一个成功创建 &#x2F;controller 节点的 Broker 会被指定为控制器</strong>。<br><img  
                     lazyload
                     alt="image"
                     data-src="https://s2.loli.net/2022/12/25/5DPETtRd9GxZUfM.png"
                      alt="image.png"
                ><br>Kafka的Broker Controller通过注册一个controller临时节点节点进行竞选，如果未set成功，则watch该节点，等待成为controller</p>
<h3 id="Controller-Broker的具体作用是什么"><a href="#Controller-Broker的具体作用是什么" class="headerlink" title="Controller Broker的具体作用是什么"></a>Controller Broker的具体作用是什么</h3><p>Controller Broker的主要职责有很多，主要是一些管理行为，主要包括以下几个方面：</p>
<ul>
<li>创建、删除主题，增加分区并分配leader分区</li>
<li>集群Broker管理（新增 Broker、Broker 主动关闭、Broker 故障)</li>
<li><strong>preferred leader</strong>选举</li>
<li>分区重分配</li>
</ul>
<h4 id="主题管理"><a href="#主题管理" class="headerlink" title="主题管理"></a>主题管理</h4><p>这里的主题管理，就是指控制器帮助我们完成对 Kafka 主题的创建、删除以及分区增加的操作。换句话说，当我们执行kafka-topics 脚本时，大部分的后台工作都是控制器来完成的。</p>
<h4 id="分区重分配"><a href="#分区重分配" class="headerlink" title="分区重分配"></a>分区重分配</h4><p>分区重分配主要是指，kafka-reassign-partitions 脚本提供的对已有主题分区进行细粒度的分配功能。这部分功能也是控制器实现的。</p>
<h4 id="集群成员管理"><a href="#集群成员管理" class="headerlink" title="集群成员管理"></a>集群成员管理</h4><p>自动检测新增 Broker、Broker 主动关闭及被动宕机。这种自动检测是依赖于前面提到的 Watch 功能和 ZooKeeper 临时节点组合实现的。比如，控制器组件会利用Watch 机制检查 ZooKeeper 的 <code>/brokers/ids</code> 节点下的子节点数量变更。目前，当有新 Broker 启动后，它会在 <code>/brokers</code> 下创建专属的 znode 节点。一旦创建完毕，ZooKeeper 会通过 Watch 机制将消息通知推送给控制器，这样，控制器就能自动地感知到这个变化，进而开启后续的新增 Broker 作业。<br>侦测 Broker 存活性则是依赖于刚刚提到的另一个机制：临时节点。每个 Broker 启动后，会在 <code>/brokers/ids </code>下创建一个临时 znode。当 Broker 宕机或主动关闭后，该 Broker 与 ZooKeeper 的会话结束，这个 znode 会被自动删除。同理，ZooKeeper 的 Watch 机制将这一变更推送给控制器，这样控制器就能知道有 Broker 关闭或宕机了，从而进行“善后”。</p>
<h4 id="数据服务"><a href="#数据服务" class="headerlink" title="数据服务"></a>数据服务</h4><p>控制器的最后一大类工作，就是向其他 Broker 提供数据服务，控制器上保存了最全的集群元数据信息，其他所有 Broker 会定期接收控制器发来的元数据更新请求，从而更新其内存中的缓存数据。<br>当控制器发现一个 broker 离开集群（通过观察相关 ZooKeeper 路径），控制器会收到消息：这个 broker 所管理的那些分区需要一个新的 Leader。控制器会依次遍历每个分区，确定谁能够作为新的 Leader，然后向所有包含新 Leader 或现有 Follower 的分区发送消息，该请求消息包含谁是新的 Leader 以及谁是 Follower 的信息。随后，新的 Leader 开始处理来自生产者和消费者的请求，Follower 用于从新的 Leader 那里进行复制。</p>
<h4 id="消费者Rebalance机制（再平衡）"><a href="#消费者Rebalance机制（再平衡）" class="headerlink" title="消费者Rebalance机制（再平衡）"></a><strong>消费者Rebalance机制（再平衡）</strong></h4><p>rebalance就是说如果消费组里的消费者数量有变化或消费的分区数有变化，kafka会重新分配消费者消费分区的关系。比如consumer group中某个消费者挂了，此时会自动把分配给他的分区交给其他的消费者，如果他又重启了，那么又会把一些分区重新交还给他。<br><strong>注意：rebalance只针对subscribe这种不指定分区消费的情况，如果通过assign这种消费方式指定了分区，kafka不会进行rebanlance。</strong><br>如下情况可能会触发消费者rebalance:</p>
<ul>
<li>消费组里的consumer增加或减少了</li>
<li>动态给topic增加了分区</li>
<li>消费组订阅了更多的topic</li>
</ul>
<p>主要有三种rebalance的策略：range()、round-robin(轮询)、sticky(粘性)。<br>Kafka 提供了消费者客户端参数partition.assignment.strategy 来设置消费者与订阅主题之间的分区分配策略。默认情况为range分配策略。</p>
<ol>
<li>range策略就是按照分区序号排序(范围分配)，假设 n＝分区数／消费者数量 &#x3D; 3， m＝分区数%消费者数量 &#x3D; 1，那么前 m 个消费者每个分配 n+1 个分区，后面的（消费者数量－m ）个消费者每个分配 n 个分区。比如分区0<del>3给一个consumer，分区4</del>6给一个consumer，分区7~9给一个consumer。</li>
<li>round-robin策略就是轮询分配，比如分区0、3、6、9给一个consumer，分区1、4、7给一个consumer，分区2、5、8给一个consumer</li>
<li>sticky策略初始时分配策略与round-robin类似，但是在rebalance的时候，需要保证如下两个原则。<ol>
<li>分区的分配要尽可能均匀</li>
<li>分区的分配尽可能与上次分配的保持相同。</li>
<li>当两者发生冲突时，第一个目标优先于第二个目标 。这样可以最大程度维持原来的分区分配的策略。比如对于第一种range情况的分配，如果第三个consumer挂了，那么重新用sticky策略分配的结果如下：<ol>
<li>consumer1除了原有的0~3，会再分配一个7</li>
<li>consumer2除了原有的4~6，会再分配8和9</li>
</ol>
</li>
</ol>
</li>
</ol>
<h4 id="同步副本-in-sync-replica-ISR-列表"><a href="#同步副本-in-sync-replica-ISR-列表" class="headerlink" title="同步副本(in-sync replica ,ISR)列表"></a>同步副本(in-sync replica ,ISR)列表</h4><p>ISR中的副本都是与Leader进行同步的副本，所以不在该列表的follower会被认为与Leader是不同步的. 那么，ISR中存在是什么副本呢？首先可以明确的是：Leader副本总是存在于ISR中。 而follower副本是否在ISR中，取决于该follower副本是否与Leader副本保持了“同步”。<br>始终保证拥有足够数量的同步副本是非常重要的。要将follower提升为Leader，它必须存在于<strong>同步副本列表中</strong>。每个分区都有一个同步副本列表，该列表由Leader分区和Controller进行更新。<br>选择一个同步副本列表中的分区作为leader 分区的过程称为<strong>clean leader election</strong>。注意，这里要与在非同步副本中选一个分区作为leader分区的过程区分开，在非同步副本中选一个分区作为leader的过程称之为<strong>unclean leader election</strong>。由于ISR是动态调整的，所以会存在ISR列表为空的情况，通常来说，非同步副本落后 Leader 太多，因此，如果选择这些副本作为新 Leader，就可能出现数据的丢失。毕竟，这些副本中保存的消息远远落后于老 Leader 中的消息。在 Kafka 中，选举这种副本的过程可以通过Broker 端参数 *_<em>*unclean.leader.election.enable <em><strong>_控制是否允许 Unclean 领导者选举。开启 Unclean 领导者选举可能会造成数据丢失，但好处是，它使得分区 Leader 副本一直存在，不至于停止对外提供服务，因此提升了高可用性。反之，禁止 Unclean Leader 选举的好处在于维护了数据的一致性，避免了消息丢失，但牺牲了高可用性。分布式系统的CAP理论说的就是这种情况。<br>不幸的是，</strong>unclean leader election</em>*的选举过程仍可能会造成数据的不一致，因为同步副本并不是</em>*完全<strong>同步的。由于复制是</strong>异步**完成的，因此无法保证follower可以获取最新消息。比如Leader分区的最后一条消息的offset是100，此时副本的offset可能不是100，这受到两个参数的影响：</p>
<ul>
<li><strong>replica.lag.time.max.ms</strong>：同步副本滞后与leader副本的时间</li>
<li><strong>zookeeper.session.timeout.ms</strong>：与zookeeper会话超时时间</li>
</ul>
<h3 id="脑裂现象"><a href="#脑裂现象" class="headerlink" title="脑裂现象"></a>脑裂现象</h3><p>如果controller Broker 挂掉了，Kafka集群必须找到可以替代的controller，集群将不能正常运转。这里面存在一个问题，很难确定Broker是挂掉了，还是仅仅只是短暂性的故障。但是，集群为了正常运转，必须选出新的controller。如果之前被取代的controller又正常了，他并不知道自己已经被取代了，那么此时集群中会出现两台controller。<br>其实这种情况是很容易发生。比如，某个controller由于GC而被认为已经挂掉，并选择了一个新的controller。在GC的情况下，在最初的controller眼中，并没有改变任何东西，该Broker甚至不知道它已经暂停了。因此，它将继续充当当前controller，这是分布式系统中的常见情况，称为脑裂。<br>假如，处于活跃状态的controller进入了长时间的GC暂停。它的ZooKeeper会话过期了，之前注册的&#x2F;controller节点被删除。集群中其他Broker会收到zookeeper的这一通知。<br><img  
                     lazyload
                     alt="image"
                     data-src="https://s2.loli.net/2022/12/25/SPvYCEBxK7ONWRh.png"
                      alt="image.png"
                ><br>由于集群中必须存在一个controller Broker，所以现在每个Broker都试图尝试成为新的controller。假设Broker 2速度比较快，成为了最新的controller Broker。此时，每个Broker会收到Broker2成为新的controller的通知，由于Broker3正在进行”stop the world”的GC，可能不会收到Broker2成为最新的controller的通知。<br><img  
                     lazyload
                     alt="image"
                     data-src="https://s2.loli.net/2022/12/25/q8lmFXLucptJDy5.png"
                      alt="image.png"
                ><br>等到Broker3的GC完成之后，仍会认为自己是集群的controller，在Broker3的眼中好像什么都没有发生一样。<br><img  
                     lazyload
                     alt="image"
                     data-src="https://s2.loli.net/2022/12/25/tCsSx1UbXGeqpjQ.png"
                      alt="image.png"
                ><br>现在，集群中出现了两个controller，它们可能一起发出具有冲突的命令，就会出现脑裂的现象。如果对这种情况不加以处理，可能会导致严重的不一致。所以需要一种方法来区分谁是集群当前最新的Controller。<br>Kafka是通过使用<strong>epoch number</strong>（纪元编号，也称为隔离令牌）来完成的。epoch number只是单调递增的数字，第一次选出Controller时，epoch number值为1，如果再次选出新的Controller，则epoch number将为2，依次单调递增。<br>每个新选出的controller通过Zookeeper 的条件递增操作获得一个全新的、数值更大的epoch number 。其他Broker 在知道当前epoch number 后，如果收到由controller发出的包含较旧(较小)epoch number的消息，就会忽略它们，即Broker根据最大的epoch number来区分当前最新的controller。</p>
<p><img  
                     lazyload
                     alt="image"
                     data-src="https://cdn.nlark.com/yuque/0/2022/png/802393/1670675351242-f859108e-2a88-4990-98b0-a9fb965a8a5d.png#averageHue=%23f8f7eb&clientId=uae02ec45-904c-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=313&id=u1f16b76b&margin=%5Bobject%20Object%5D&name=image.png&originHeight=576&originWidth=1360&originalType=binary&ratio=1&rotation=0&showTitle=false&size=117535&status=done&style=stroke&taskId=u30fd1dcb-2592-4e9a-a4cd-30d0546a70c&title=&width=740"
                      alt="image.png"
                ><br>上图，Broker3向Broker1发出命令:让Broker1上的某个分区副本成为leader，该消息的epoch number值为1。于此同时，Broker2也向Broker1发送了相同的命令，不同的是，该消息的epoch number值为2，此时Broker1只听从Broker2的命令(由于其epoch number较大)，会忽略Broker3的命令，从而避免脑裂的发生。</p>
<h1 id="Kafka优化策略"><a href="#Kafka优化策略" class="headerlink" title="Kafka优化策略"></a>Kafka优化策略</h1><h2 id="常见核心配置"><a href="#常见核心配置" class="headerlink" title="常见核心配置"></a>常见核心配置</h2><h3 id="内存缓冲的大小：buffer-memory"><a href="#内存缓冲的大小：buffer-memory" class="headerlink" title="内存缓冲的大小：buffer.memory"></a>内存缓冲的大小：buffer.memory</h3><ol>
<li>生产者投递消息先存放在本地缓冲区中，将消息组装成n多个不同的Batch，在通过send线程将缓冲区的数据批量的形式发送给kafka服务器端存放。</li>
<li>生产者本地内存缓冲区如果设置太小了，在高并发情况下有可能会发生内存溢出，导致生产者无法继续写入消息到缓冲区卡死。</li>
<li>实际生产环境中，根据压力测试情况下，合理设置内存缓冲区大小。</li>
</ol>
<p>参数：<code>buffer.memory</code></p>
<h3 id="最大请求大小：“max-request-size”"><a href="#最大请求大小：“max-request-size”" class="headerlink" title="最大请求大小：“max.request.size”"></a>最大请求大小：“max.request.size”</h3><p>该参数kafkamq服务器端限制接受的消息</p>
<h3 id="重试策略“retries”和“retries-backoff-ms”"><a href="#重试策略“retries”和“retries-backoff-ms”" class="headerlink" title="重试策略“retries”和“retries.backoff.ms”"></a>重试策略“retries”和“retries.backoff.ms”</h3><p>该参数设置定重试的次数、间隔时间</p>
<h3 id="确认机制：acks"><a href="#确认机制：acks" class="headerlink" title="确认机制：acks"></a>确认机制：acks</h3><p>建议设置为1<br>ACK 参数配置：</p>
<ol>
<li>0：Producer 不等待 Broker 的 ACK，这提供了最低延迟，Broker 一收到数据还没有写入磁盘就已经返回，当 Broker 故障时有可能丢失数据。</li>
<li>1：Producer 等待 Broker 的 ACK，Partition 的 Leader 落盘成功后返回 ACK，如果在 Follower 同步成功之前 Leader 故障，那么将会丢失数据。</li>
<li>-1（all）：Producer 等待 Broker 的 ACK，Partition 的 Leader 和 Follower 全部落盘成功后才返回 ACK。但是在 Broker 发送 ACK 时，Leader 发生故障，则会造成数据重复。</li>
</ol>
<p><strong>具体看业务要求：-1 all  延迟概率一定很低 0 延迟概率为适中1</strong></p>
<h3 id="消费者分区的个数"><a href="#消费者分区的个数" class="headerlink" title="消费者分区的个数"></a>消费者分区的个数</h3><p>消费者怎么知道我应该从哪个位置开始消费呢？应该有一个记录分组对应消费分区offset位置。</p>
<ul>
<li>在老的版本kafka中是记录在zk上，记录在zk上频繁读写操作，性能不是很好。</li>
<li>在新的版本kafka中，消费者消费分区中的消息是记录在topic主题日志文件中，默认的情况下分成50个文件记录。</li>
</ul>
<p>为什么消费者需要使用50个文件记录消费者消费记录呢？</p>
<ul>
<li>如果消费者（分组）比较多的，都记录在同一个日志文件中，读写操作就非常麻烦。</li>
</ul>
<p>消费者怎么知道我应该读取那个日志文件 知道从那个offset开始消费呢？</p>
<ol>
<li>消费者消费消息的时候：key&#x3D;group-id.topic.partition</li>
<li>group-id.topic.partition&#x3D;mayikt.mttopic.0</li>
<li>(key&#x3D;group-id.topic.partition)%consumer_offsets.size(50)&#x3D;12</li>
<li>Offset消费记录 记录在consumer_offsets-12文件夹</li>
<li>记录Offset消费记录 的是consumer分组对应消费记录 不是记录单个消费者消费记录。</li>
</ol>
<p>–记录当前分组消费的记录—<br>offsets.topic.replication.factor 参数的约束，默认值为3（注意：该参数的使用限制在0.11.0.0版本发生变化），分区数可以通过 offsets.topic.num.partitions 参数设置，默认值为50。</p>
<h2 id="优化策略"><a href="#优化策略" class="headerlink" title="优化策略"></a>优化策略</h2><h3 id="Broker优化"><a href="#Broker优化" class="headerlink" title="Broker优化"></a>Broker优化</h3><ol>
<li>replica复制配置</li>
</ol>
<p>follow从leader拉取消息进行同步数据</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">num.replica.fetchers  拉取线程数 配置多可以提高follower的I/O并发度，单位时间内leader持有更多请求，相应负载会增大，需要根据机器硬件资源做权衡</span><br><span class="line">replica.fetch.min.bytes=<span class="number">1</span>  拉取最小字节数 默认配置为<span class="number">1</span>字节，否则读取消息不及时</span><br><span class="line">replica.fetch.max.bytes= <span class="number">5</span> * <span class="number">1024</span> * <span class="number">1024</span> 拉取最大字节数  默认为1MB，这个值太小，5MB为宜，根据业务情况调整</span><br><span class="line">replica.fetch.wait.max.ms follow 最大等待时间 </span><br></pre></td></tr></table></figure>

<ol start="2">
<li>压缩速度 compression.type：压缩的速度上lz4&#x3D;snappy&lt;gzip。</li>
</ol>
<h3 id="Produer优化"><a href="#Produer优化" class="headerlink" title="Produer优化"></a>Produer优化</h3><p>幂等性：enable.idempotence<br>是否使用幂等性。如果设置为true，表示producer将确保每一条消息只会存放一份；如果设置为false，则表示producer因发送数据到broker失败重试使，可能往数据流中写入多分重试的消息。<br>注意：如果使用idempotence，即enable.idempotence为true，那么要求配置项max.in.flight.requests.per.connection的值必须小于或等于5；配置项retries的值必须大于0；acks配置项必须设置为all。如果这些值没有被用户明确地设置，那么系统将自动选择合适的值。如果设置　　的值不合适，那么会抛出ConfigException异常。</p>
<h3 id="网络和IO线程配置优化"><a href="#网络和IO线程配置优化" class="headerlink" title="网络和IO线程配置优化"></a>网络和IO线程配置优化</h3><p>1.num.network.threads：Broker处理消息的最大线程数<br>2.num.io.threads：Broker处理磁盘IO的线程数<br>一般num.network.threads主要处理网络io，读写缓冲区数据，配置线程数量为cpu核数加1<br>num.io.threads主要进行磁盘io操作，高峰期可能会发生IO等待，因此配置需要大些，配置线程数量为cpu核数2倍，最大不超过3倍.</p>
<h3 id="日志保留策略配置"><a href="#日志保留策略配置" class="headerlink" title="日志保留策略配置"></a>日志保留策略配置</h3><p>生产者投递消息到kafka的mq中，消费者获取到消息之后不会立即被删除，会有一个日志保留策略。</p>
<ol>
<li>减少日志保留时间，建议三天或则更多时间。log.retention.hours&#x3D;72</li>
<li>分段文件配置1GB， 默认是500mb 有利于快速回收磁盘空间，重启kafka加载也会加快(如果文件过小，则文件数量比较多，kafka启动时是单线程扫描目录(log.dir)下所有数据文件)，文件较多时性能会稍微降低。log.segment.bytes&#x3D;1073741824<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">##日志滚动的周期时间，到达指定周期时间时，强制生成一个新的segment</span><br><span class="line">log.roll.hours=<span class="number">72</span></span><br><span class="line">##segment的索引文件最大尺寸限制，即时log.segment.bytes没达到，也会生成一个新的segment</span><br><span class="line">log.index.size.max.bytes=<span class="number">10</span>*<span class="number">1024</span>*<span class="number">1024</span></span><br><span class="line">##控制日志segment文件的大小，超出该大小则追加到一个新的日志segment文件中（-<span class="number">1</span>表示没有限制）</span><br><span class="line">log.segment.bytes=<span class="number">1014</span>*<span class="number">1024</span>*<span class="number">1024</span></span><br></pre></td></tr></table></figure></li>
</ol>
<h3 id="log数据文件刷盘策略"><a href="#log数据文件刷盘策略" class="headerlink" title="log数据文件刷盘策略"></a>log数据文件刷盘策略</h3><p>当我们把数据写入到文件系统之后，数据其实在操作系统的page cache里面，并没有刷到磁盘上去。如果此时操作系统挂了，其实数据就丢了。</p>
<ol>
<li>每当producer写入10000条消息时，刷数据到磁盘 配置为：log.flush.interval.messages&#x3D;10000</li>
<li>每间隔1秒钟时间，刷数据到磁盘。log.flush.interval.ms&#x3D;1000</li>
</ol>
<h3 id="配置优化案例（重要）"><a href="#配置优化案例（重要）" class="headerlink" title="配置优化案例（重要）"></a>配置优化案例（重要）</h3><p>Broker<br>num.replica.fetchers： 适量提高同步leader副本线程<br>Producer<br>inger.ms 0 或者1 定时将批量消息发送到Broker中<br>Consumer<br>auto.commit.enable —配置为手动提交offset</p>
<h1 id="Docker环境下的Kafka环境搭建（单机）"><a href="#Docker环境下的Kafka环境搭建（单机）" class="headerlink" title="Docker环境下的Kafka环境搭建（单机）"></a>Docker环境下的Kafka环境搭建（单机）</h1><p><a class="link"   href="https://www.lixueduan.com/posts/kafka/01-install/" >https://www.lixueduan.com/posts/kafka/01-install/<i class="fas fa-external-link-alt"></i></a></p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">version:</span> <span class="string">&quot;3&quot;</span></span><br><span class="line"><span class="attr">services:</span></span><br><span class="line">  <span class="attr">zookeeper:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">&#x27;bitnami/zookeeper:latest&#x27;</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&#x27;2181:2181&#x27;</span></span><br><span class="line">    <span class="attr">environment:</span></span><br><span class="line">      <span class="comment"># 匿名登录--必须开启</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">ALLOW_ANONYMOUS_LOGIN=yes</span></span><br><span class="line">    <span class="comment">#volumes:</span></span><br><span class="line">      <span class="comment">#- ./zookeeper:/bitnami/zookeeper</span></span><br><span class="line">  <span class="comment"># 该镜像具体配置参考 https://github.com/bitnami/bitnami-docker-kafka/blob/master/README.md</span></span><br><span class="line">  <span class="attr">kafka:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">&#x27;bitnami/kafka:2.8.0&#x27;</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&#x27;9092:9092&#x27;</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&#x27;9999:9999&#x27;</span></span><br><span class="line">    <span class="attr">environment:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">KAFKA_BROKER_ID=1</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">KAFKA_CFG_LISTENERS=PLAINTEXT://:9092</span></span><br><span class="line">      <span class="comment"># 客户端访问地址，更换成自己的</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">KAFKA_CFG_ZOOKEEPER_CONNECT=zookeeper:2181</span></span><br><span class="line">      <span class="comment"># 允许使用PLAINTEXT协议(镜像中默认为关闭,需要手动开启)</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">ALLOW_PLAINTEXT_LISTENER=yes</span></span><br><span class="line">      <span class="comment"># 关闭自动创建 topic 功能</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">KAFKA_CFG_AUTO_CREATE_TOPICS_ENABLE=false</span></span><br><span class="line">      <span class="comment"># 全局消息过期时间 6 小时(测试时可以设置短一点)</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">KAFKA_CFG_LOG_RETENTION_HOURS=6</span></span><br><span class="line">      <span class="comment"># 开启JMX监控</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">JMX_PORT=9999</span></span><br><span class="line">    <span class="comment">#volumes:</span></span><br><span class="line">      <span class="comment">#- ./kafka:/bitnami/kafka</span></span><br><span class="line">    <span class="attr">depends_on:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">zookeeper</span></span><br><span class="line">  <span class="comment"># Web 管理界面 另外也可以用exporter+prometheus+grafana的方式来监控 https://github.com/danielqsj/kafka_exporter</span></span><br><span class="line">  <span class="attr">kafka_manager:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">&#x27;hlebalbau/kafka-manager:latest&#x27;</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&quot;9000:9000&quot;</span></span><br><span class="line">    <span class="attr">environment:</span></span><br><span class="line">      <span class="attr">ZK_HOSTS:</span> <span class="string">&quot;zookeeper:2181&quot;</span></span><br><span class="line">      <span class="attr">APPLICATION_SECRET:</span> <span class="string">letmein</span></span><br><span class="line">    <span class="attr">depends_on:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">zookeeper</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">kafka</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h1 id="SpringBoot启动和配置kafka"><a href="#SpringBoot启动和配置kafka" class="headerlink" title="SpringBoot启动和配置kafka"></a>SpringBoot启动和配置kafka</h1><p>SpringBoot中很多kafka的使用技巧，简单记录和探索</p>
<h2 id="1-引入依赖"><a href="#1-引入依赖" class="headerlink" title="1. 引入依赖"></a>1. 引入依赖</h2><p>引入基本的maven的pom文件，包含kafka的Server</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.kafka<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-kafka<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">  <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-test<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">scope</span>&gt;</span>test<span class="tag">&lt;/<span class="name">scope</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.kafka<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-kafka-test<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">scope</span>&gt;</span>test<span class="tag">&lt;/<span class="name">scope</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">  <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.projectlombok<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>lombok<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">  <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-web<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">build</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">plugins</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.maven.plugins<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>maven-compiler-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.8.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">encoding</span>&gt;</span>UTF-8<span class="tag">&lt;/<span class="name">encoding</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-maven-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">plugins</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">build</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h2 id="2-使用Spring-Test启动一个kafka"><a href="#2-使用Spring-Test启动一个kafka" class="headerlink" title="2. 使用Spring Test启动一个kafka"></a>2. 使用Spring Test启动一个kafka</h2><p>只要maven项目中引入<code>spring-kafka-test</code>就可以直接使用springboot启动一个kafka的Server，非常方便在开发阶段</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 启动kafka dev环境的实例</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@SpringBootTest(classes = ApplicationTests.class)</span></span><br><span class="line"><span class="meta">@EmbeddedKafka(count = 4, ports = &#123;9092, 9093, 9094, 9095&#125;)</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ApplicationTests</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 启动kafka</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * dev test模式</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@throws</span> IOException</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">startServer</span><span class="params">()</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        System.in.read();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="3-初步测试"><a href="#3-初步测试" class="headerlink" title="3. 初步测试"></a>3. 初步测试</h2><h3 id="3-1-编写生产者和消费者的demo代码"><a href="#3-1-编写生产者和消费者的demo代码" class="headerlink" title="3.1 编写生产者和消费者的demo代码"></a>3.1 编写生产者和消费者的demo代码</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * kafka的demo</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> zhangshuaike</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@SpringBootApplication</span></span><br><span class="line"><span class="meta">@RestController</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">KafkaDemoApplication</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        SpringApplication.run(KafkaDemoApplication.class, args);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="keyword">private</span> KafkaTemplate&lt;Object, Object&gt; template;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@GetMapping(&quot;/send/&#123;input&#125;&quot;)</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">sendFoo</span><span class="params">(<span class="meta">@PathVariable</span> String input)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.template.send(<span class="string">&quot;topic_input&quot;</span>, input);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@KafkaListener(id = &quot;webGroup&quot;, topics = &quot;topic_input&quot;)</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">listen</span><span class="params">(String input)</span> &#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;input value:&quot;</span> + input);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="3-2-发送测试"><a href="#3-2-发送测试" class="headerlink" title="3.2 发送测试"></a>3.2 发送测试</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">curl http:<span class="comment">//127.0.0.1:8080/send/test</span></span><br></pre></td></tr></table></figure>
<h2 id="4-带回调函数的生产者"><a href="#4-带回调函数的生产者" class="headerlink" title="4. 带回调函数的生产者"></a>4. 带回调函数的生产者</h2><p>kafkaTemplate提供了一个回调方法addCallback，我们可以在回调方法中监控消息是否发送成功 或 失败时做补偿处理，有两种写法。</p>
<h3 id="4-1-第一种"><a href="#4-1-第一种" class="headerlink" title="4.1 第一种"></a>4.1 第一种</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@GetMapping(&quot;/one/&#123;message&#125;&quot;)</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">sendMessage2</span><span class="params">(<span class="meta">@PathVariable(&quot;message&quot;)</span> String callbackMessage)</span> &#123;</span><br><span class="line">    kafkaTemplate.send(<span class="string">&quot;topic1&quot;</span>, callbackMessage).addCallback(success -&gt; &#123;</span><br><span class="line">        <span class="comment">// 消息发送到的topic</span></span><br><span class="line">        <span class="type">String</span> <span class="variable">topic</span> <span class="operator">=</span> success.getRecordMetadata().topic();</span><br><span class="line">        <span class="comment">// 消息发送到的分区</span></span><br><span class="line">        <span class="type">int</span> <span class="variable">partition</span> <span class="operator">=</span> success.getRecordMetadata().partition();</span><br><span class="line">        <span class="comment">// 消息在分区内的offset</span></span><br><span class="line">        <span class="type">long</span> <span class="variable">offset</span> <span class="operator">=</span> success.getRecordMetadata().offset();</span><br><span class="line">        System.out.println(<span class="string">&quot;发送消息成功:&quot;</span> + topic + <span class="string">&quot;-&quot;</span> + partition + <span class="string">&quot;-&quot;</span> + offset);</span><br><span class="line">    &#125;, failure -&gt; &#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;发送消息失败:&quot;</span> + failure.getMessage());</span><br><span class="line">    &#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="4-2-第二种"><a href="#4-2-第二种" class="headerlink" title="4.2 第二种"></a>4.2 第二种</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@GetMapping(&quot;/two/&#123;message&#125;&quot;)</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">sendMessage3</span><span class="params">(<span class="meta">@PathVariable(&quot;message&quot;)</span> String callbackMessage)</span> &#123;</span><br><span class="line">    kafkaTemplate.send(<span class="string">&quot;topic1&quot;</span>, callbackMessage).addCallback(<span class="keyword">new</span> <span class="title class_">ListenableFutureCallback</span>&lt;SendResult&lt;String, Object&gt;&gt;() &#123;</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">onFailure</span><span class="params">(Throwable ex)</span> &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;发送消息失败：&quot;</span>+ex.getMessage());</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">onSuccess</span><span class="params">(SendResult&lt;String, Object&gt; result)</span> &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;发送消息成功：&quot;</span> + result.getRecordMetadata().topic() + <span class="string">&quot;-&quot;</span></span><br><span class="line">                    + result.getRecordMetadata().partition() + <span class="string">&quot;-&quot;</span> + result.getRecordMetadata().offset());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="5-自定义分区器"><a href="#5-自定义分区器" class="headerlink" title="5. 自定义分区器"></a>5. 自定义分区器</h2><p>kafka中每个topic被划分为多个分区，那么生产者将消息发送到topic时，具体要追加到哪个分区？这就是分区策略，Kafka 为我们提供了默认的分区策略，同时它也支持自定义分区策略。其路由机制为：</p>
<ol>
<li>若发送消息时指定了分区（即自定义分区策略），则直接将消息append到指定分区；</li>
<li>若发送消息时未指定 patition，但指定了 key（kafka允许为每条消息设置一个key），则对key值进行hash计算，根据计算结果路由到指定分区，这种情况下可以保证同一个 Key 的所有消息都进入到相同的分区；</li>
<li>patition 和 key 都未指定，则使用kafka默认的分区策略，轮询选出一个 patition；</li>
</ol>
<p>我们自定义一个分区策略，将消息发送到我们指定的partition，首先新建一个分区器类实现Partitioner接口，重写方法，<strong>其中partition方法的返回值就表示将消息发送到几号分区。</strong></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">CustomizePartitioner</span> <span class="keyword">implements</span> <span class="title class_">Partitioner</span> &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">partition</span><span class="params">(String s, Object o, <span class="type">byte</span>[] bytes, Object o1, <span class="type">byte</span>[] bytes1, Cluster cluster)</span> &#123;</span><br><span class="line">        <span class="comment">//自定义分区规则（这里假设全部发到0号分区）</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">close</span><span class="params">()</span> &#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">configure</span><span class="params">(Map&lt;String, ?&gt; map)</span> &#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在application.propertise中配置自定义分区器，配置的值就是分区器类的全路径名</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"># 自定义分区器</span><br><span class="line">spring.kafka.producer.properties.partitioner.class=com.felix.kafka.producer.CustomizePartitioner</span><br></pre></td></tr></table></figure>
<h2 id="6-kafka事务提交"><a href="#6-kafka事务提交" class="headerlink" title="6.kafka事务提交"></a>6.kafka事务提交</h2><p>如果在发送消息时需要创建事务，可以使用 KafkaTemplate 的 executeInTransaction 方法来声明事务</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 发送事务消息，需要处理以下事项：</span></span><br><span class="line"><span class="comment"> * 1. 设置spring</span></span><br><span class="line"><span class="comment"> *    kafka:</span></span><br><span class="line"><span class="comment"> *     producer:</span></span><br><span class="line"><span class="comment"> *       retries: 3 #重试次数</span></span><br><span class="line"><span class="comment"> *       acks: all</span></span><br><span class="line"><span class="comment"> *       # 加事务前缀，自动给producer开启事务，所有加</span></span><br><span class="line"><span class="comment"> *       transaction-id-prefix: tx_</span></span><br><span class="line"><span class="comment"> * 2.方法上增加  <span class="doctag">@Transactional</span></span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@GetMapping(&quot;/send&quot;)</span></span><br><span class="line"><span class="meta">@SuppressWarnings(&quot;all&quot;)</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">sendMessageTransaction</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="comment">//生命事务，后面报错消息不会发出去</span></span><br><span class="line">    kafkaTemplate.executeInTransaction(operations -&gt;&#123;</span><br><span class="line">        operations.send(<span class="string">&quot;transaction&quot;</span>,<span class="string">&quot;慢慢沉淀&quot;</span>);</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">RuntimeException</span>(<span class="string">&quot;fail&quot;</span>);</span><br><span class="line">    &#125;);</span><br><span class="line">    <span class="comment">//不声明事务，后面保存但前端消息已经发送成功了</span></span><br><span class="line">    kafkaTemplate.send(<span class="string">&quot;transaction&quot;</span>,<span class="string">&quot;慢慢沉淀，但是我不带事务&quot;</span>);</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">RuntimeException</span>(<span class="string">&quot;fail&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="7-消费者指定参数"><a href="#7-消费者指定参数" class="headerlink" title="7. 消费者指定参数"></a>7. 消费者指定参数</h2><p>指定topic、partition、offset消费<br>前面我们在监听消费topic1的时候，监听的是topic1上所有的消息，如果我们想指定topic、指定partition、指定offset来消费呢？也很简单，@KafkaListener注解已全部为我们提供。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Title</span> 指定topic、partition、offset消费</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Description</span> 同时监听topic1和topic2，监听topic1的0号分区、</span></span><br><span class="line"><span class="comment"> * topic2的 &quot;0号和1号&quot; 分区，指向1号分区的offset初始值为8</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> record</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@KafkaListener(id=&quot;consumer1&quot;,groupId = &quot;felix-group&quot;,topicPartitions = &#123;</span></span><br><span class="line"><span class="meta">        @TopicPartition(topic = &quot;topic1&quot;,partitions = &#123;&quot;0&quot;&#125;),</span></span><br><span class="line"><span class="meta">        @TopicPartition(topic = &quot;topic2&quot;,partitions = &quot;0&quot;,</span></span><br><span class="line"><span class="meta">                partitionOffsets = @PartitionOffset(partition = &quot;1&quot;,initialOffset = &quot;8&quot;))</span></span><br><span class="line"><span class="meta">&#125;)</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">onMessage2</span><span class="params">(ConsumerRecord&lt;?,?&gt; record)</span>&#123;</span><br><span class="line">    System.out.println(<span class="string">&quot;topic:&quot;</span>+record.topic()+<span class="string">&quot;partition:&quot;</span>+record.partition()+<span class="string">&quot;offset:&quot;</span>+record.offset()+<span class="string">&quot;value:&quot;</span>+record.value());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>属性解释：</p>
<ol>
<li>id：消费者ID；</li>
<li>groupId：消费组ID；</li>
<li>topics：监听的topic，可监听多个；</li>
<li>topicPartitions：可配置更加详细的监听信息，可指定topic、parition、offset监听。</li>
</ol>
<p>上面onMessage2监听的含义：监听topic1的0号分区，同时监听topic2的0号分区和topic2的1号分区里面offset从8开始的消息。<br>注意：topics和topicPartitions不能同时使用；</p>
<h2 id="8-消费者批量消费"><a href="#8-消费者批量消费" class="headerlink" title="8.消费者批量消费"></a>8.消费者批量消费</h2><h3 id="8-1设置application-properties开启批量消费即可"><a href="#8-1设置application-properties开启批量消费即可" class="headerlink" title="8.1设置application.properties开启批量消费即可"></a>8.1设置application.properties开启批量消费即可</h3><figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 设置批量消费</span></span><br><span class="line"><span class="attr">spring.kafka.listener.type</span>=<span class="string">batch</span></span><br><span class="line"><span class="comment"># 批量消费每次最多消费多少条消息</span></span><br><span class="line"><span class="attr">spring.kafka.consumer.max-poll-records</span>=<span class="string">50</span></span><br></pre></td></tr></table></figure>
<h3 id="8-2-接收消息时用List来接收，监听代码如下："><a href="#8-2-接收消息时用List来接收，监听代码如下：" class="headerlink" title="8.2 接收消息时用List来接收，监听代码如下："></a>8.2 接收消息时用List来接收，监听代码如下：</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@KafkaListener(id=&quot;consumer2&quot;,groupId = &quot;felix-group&quot;,topics = &quot;topic1&quot; )</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">onMesssage</span><span class="params">(List&lt;ConsumerRecord&lt;?,?&gt;&gt; records)</span>&#123;</span><br><span class="line">    System.out.println(<span class="string">&quot;&gt;&gt;&gt;批量消费一次，records.size()=&quot;</span>+records.size());</span><br><span class="line">    <span class="keyword">for</span>(ConsumerRecord&lt;?,?&gt; record:records)&#123;</span><br><span class="line">        System.out.println(record.value());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="9-ConsumerAwareListenerErrorHandler异常处理器"><a href="#9-ConsumerAwareListenerErrorHandler异常处理器" class="headerlink" title="9.ConsumerAwareListenerErrorHandler异常处理器"></a>9.ConsumerAwareListenerErrorHandler异常处理器</h2><p>通过异常处理器，我们可以处理consumer在消费时发生的异常。<br>新建一个 ConsumerAwareListenerErrorHandler 类型的异常处理方法，用@Bean注入，BeanName默认就是方法名，然后我们将这个异常处理器的BeanName放到@KafkaListener注解的errorHandler属性里面，当监听抛出异常的时候，则会自动调用异常处理器。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//异常处理</span></span><br><span class="line"><span class="comment">// 新建一个异常处理器，用@Bean注入</span></span><br><span class="line"><span class="meta">@Bean</span></span><br><span class="line"><span class="keyword">public</span> ConsumerAwareListenerErrorHandler <span class="title function_">consumerAwareErrorHandler</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="keyword">return</span> (message,exception,consumer)-&gt;&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;消费异常：&quot;</span>+message.getPayload());</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">null</span>;</span><br><span class="line">    &#125;;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//将这个异常处理器的BeanName放到@KafkaListener注解的errorHandler属性里面</span></span><br><span class="line"><span class="meta">@KafkaListener(topics = &#123;&quot;topic1&quot;&#125;,errorHandler = &quot;consumerAwareErrorHandler&quot;)</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">onMessage4</span><span class="params">(ConsumerRecord&lt;?,?&gt; record)</span> <span class="keyword">throws</span> Exception&#123;</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">Exception</span>(<span class="string">&quot;简单消费-模拟异常&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 批量消费也一样，异常处理器的message.getPayload()也可以拿到各条消息的信息</span></span><br><span class="line"><span class="meta">@KafkaListener(topics = &quot;topic1&quot;,errorHandler=&quot;consumerAwareErrorHandler&quot;)</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">onMessage5</span><span class="params">(List&lt;ConsumerRecord&lt;?,?&gt;&gt; records)</span> <span class="keyword">throws</span> Exception&#123;</span><br><span class="line">    System.out.println(<span class="string">&quot;批量消费一次...&quot;</span>);</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">Exception</span>(<span class="string">&quot;批量消费-模拟异常&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="10-消费过滤器"><a href="#10-消费过滤器" class="headerlink" title="10.消费过滤器"></a>10.消费过滤器</h2><p>消息过滤器可以在消息抵达consumer之前被拦截，在实际应用中，我们可以根据自己的业务逻辑，筛选出需要的信息再交由KafkaListener处理，不需要的消息则过滤掉。<br>配置消息过滤只需要为 监听器工厂 配置一个RecordFilterStrategy（消息过滤策略），返回true的时候消息将会被抛弃，返回false时，消息能正常抵达监听容器。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.example.kafka.consumer;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.ConsumerRecord;</span><br><span class="line"><span class="keyword">import</span> org.springframework.beans.factory.annotation.Autowired;</span><br><span class="line"><span class="keyword">import</span> org.springframework.context.annotation.Bean;</span><br><span class="line"><span class="keyword">import</span> org.springframework.kafka.annotation.KafkaListener;</span><br><span class="line"><span class="keyword">import</span> org.springframework.kafka.annotation.PartitionOffset;</span><br><span class="line"><span class="keyword">import</span> org.springframework.kafka.annotation.TopicPartition;</span><br><span class="line"><span class="keyword">import</span> org.springframework.kafka.config.ConcurrentKafkaListenerContainerFactory;</span><br><span class="line"><span class="keyword">import</span> org.springframework.kafka.core.ConsumerFactory;</span><br><span class="line"><span class="keyword">import</span> org.springframework.kafka.listener.ConsumerAwareListenerErrorHandler;</span><br><span class="line"><span class="keyword">import</span> org.springframework.messaging.handler.annotation.SendTo;</span><br><span class="line"><span class="keyword">import</span> org.springframework.stereotype.Component;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">KafkaConsumer</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    ConsumerFactory consumerFactory;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//消息过滤器</span></span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="keyword">public</span> ConcurrentKafkaListenerContainerFactory <span class="title function_">filterContainerFactory</span><span class="params">()</span>&#123;</span><br><span class="line">        ConcurrentKafkaListenerContainerFactory factory=<span class="keyword">new</span> <span class="title class_">ConcurrentKafkaListenerContainerFactory</span>();</span><br><span class="line">        factory.setConsumerFactory(consumerFactory);</span><br><span class="line">        <span class="comment">//被过滤器的消息将被丢弃</span></span><br><span class="line">        factory.setAckDiscarded(<span class="literal">true</span>);</span><br><span class="line">        <span class="comment">//消息过滤策略</span></span><br><span class="line">        factory.setRecordFilterStrategy(consumerRecord -&gt; &#123;</span><br><span class="line">            <span class="keyword">if</span>(Integer.parseInt(consumerRecord.value().toString())%<span class="number">2</span>==<span class="number">0</span>)&#123;</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">//返回true消息则被过滤</span></span><br><span class="line">            <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">        &#125;);</span><br><span class="line">        <span class="keyword">return</span> factory;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//消息过滤监听</span></span><br><span class="line">    <span class="meta">@KafkaListener(topics = &#123;&quot;topic1&quot;&#125;,containerFactory = &quot;filterContainerFactory&quot;)</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">onMessage6</span><span class="params">(ConsumerRecord&lt;?,?&gt; record)</span>&#123;</span><br><span class="line">        System.out.println(record.value());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>上面实现了一个”过滤奇数、接收偶数”的过滤策略，我们向topic1发送0-99总共100条消息，看一下监听器的消费情况，可以看到监听器只消费了偶数，</p>
<h2 id="11-消息转发"><a href="#11-消息转发" class="headerlink" title="11. 消息转发"></a>11. 消息转发</h2><p>在实际开发中，我们可能有这样的需求，应用A从TopicA获取到消息，经过处理后转发到TopicB，再由应用B监听处理消息，即一个应用处理完成后将该消息转发至其他应用，完成消息的转发。<br>在SpringBoot集成Kafka实现消息的转发也很简单，只需要通过一个@SendTo注解，被注解方法的return值即转发的消息内容，如下</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">  * <span class="doctag">@Title</span> 消息转发</span></span><br><span class="line"><span class="comment">  * <span class="doctag">@Description</span> 从topic1接收到的消息经过处理后转发到topic2</span></span><br><span class="line"><span class="comment">  * <span class="doctag">@param</span> record</span></span><br><span class="line"><span class="comment">  * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line"> <span class="meta">@KafkaListener(topics = &#123;&quot;topic&quot;&#125;)</span></span><br><span class="line"> <span class="meta">@SendTo(&quot;topic2&quot;)</span></span><br><span class="line"> <span class="keyword">public</span> String <span class="title function_">onMessage7</span><span class="params">(ConsumerRecord&lt;?,?&gt; record)</span>&#123;</span><br><span class="line">     <span class="keyword">return</span> record.value()+<span class="string">&quot;-forward message&quot;</span>;</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure>
<h2 id="12-定时启动，停止监听器"><a href="#12-定时启动，停止监听器" class="headerlink" title="12. 定时启动，停止监听器"></a>12. 定时启动，停止监听器</h2><p>默认情况下，当消费者项目启动的时候，监听器就开始工作，监听消费发送到指定topic的消息，那如果我们不想让监听器立即工作，想让它在我们指定的时间点开始工作，或者在我们指定的时间点停止工作，该怎么处理呢——使用KafkaListenerEndpointRegistry，下面我们就来实现：<br>① 禁止监听器自启动；<br>② 创建两个定时任务，一个用来在指定时间点启动定时器，另一个在指定时间点停止定时器；<br>新建一个定时任务类，用注解@EnableScheduling声明，KafkaListenerEndpointRegistry 在SpringIO中已经被注册为Bean，直接注入，设置禁止KafkaListener自启动，</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@EnableScheduling</span></span><br><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">CronTimer</span> &#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@KafkaListener</span>注解所标注的方法并不会在IOC容器中被注册为Bean，</span></span><br><span class="line"><span class="comment">     * 而是会被注册在KafkaListenerEndpointRegistry中，</span></span><br><span class="line"><span class="comment">     * 而KafkaListenerEndpointRegistry在SpringIOC中已经被注册为Bean</span></span><br><span class="line"><span class="comment">     **/</span></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="keyword">private</span> KafkaListenerEndpointRegistry registry;</span><br><span class="line">    </span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="keyword">private</span> ConsumerFactory consumerFactory;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 监听器容器工厂(设置禁止KafkaListener自启动)</span></span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="keyword">public</span> ConcurrentKafkaListenerContainerFactory <span class="title function_">delayContainerFactory</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="type">ConcurrentKafkaListenerContainerFactory</span> <span class="variable">container</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ConcurrentKafkaListenerContainerFactory</span>();</span><br><span class="line">        container.setConsumerFactory(consumerFactory);</span><br><span class="line">        <span class="comment">//禁止KafkaListener自启动</span></span><br><span class="line">        container.setAutoStartup(<span class="literal">false</span>);</span><br><span class="line">        <span class="keyword">return</span> container;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 监听器</span></span><br><span class="line">    <span class="meta">@KafkaListener(id=&quot;timingConsumer&quot;,topics = &quot;topic1&quot;,containerFactory = &quot;delayContainerFactory&quot;)</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">onMessage1</span><span class="params">(ConsumerRecord&lt;?, ?&gt; record)</span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;消费成功：&quot;</span>+record.topic()+<span class="string">&quot;-&quot;</span>+record.partition()+<span class="string">&quot;-&quot;</span>+record.value());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 定时启动监听器</span></span><br><span class="line">    <span class="meta">@Scheduled(cron = &quot;0 42 11 * * ? &quot;)</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">startListener</span><span class="params">()</span> &#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;启动监听器...&quot;</span>);</span><br><span class="line">        <span class="comment">// &quot;timingConsumer&quot;是@KafkaListener注解后面设置的监听器ID,标识这个监听器</span></span><br><span class="line">        <span class="keyword">if</span> (!registry.getListenerContainer(<span class="string">&quot;timingConsumer&quot;</span>).isRunning()) &#123;</span><br><span class="line">            registry.getListenerContainer(<span class="string">&quot;timingConsumer&quot;</span>).start();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//registry.getListenerContainer(&quot;timingConsumer&quot;).resume();</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 定时停止监听器</span></span><br><span class="line">    <span class="meta">@Scheduled(cron = &quot;0 45 11 * * ? &quot;)</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">shutDownListener</span><span class="params">()</span> &#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;关闭监听器...&quot;</span>);</span><br><span class="line">        registry.getListenerContainer(<span class="string">&quot;timingConsumer&quot;</span>).pause();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>启动项目，触发生产者向topic1发送消息，可以看到consumer没有消费，因为这时监听器还没有开始工作</p>
<h1 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h1><p><a class="link"   href="https://tech.meituan.com/2015/01/13/kafka-fs-design-theory.html" >Kafka文件存储机制那些事<i class="fas fa-external-link-alt"></i></a></p>
<p><a class="link"   href="https://blog.csdn.net/qq_28807077/article/details/123312129" >Kafka如何保证消息的可靠性_我是你亲爱的航哥的博客-CSDN博客_kafka保证消息可靠性<i class="fas fa-external-link-alt"></i></a></p>
<p><a class="link"   href="https://www.51cto.com/article/719483.html" >谈谈你对Kafka副本Leader选举原理的理解？-51CTO.COM<i class="fas fa-external-link-alt"></i></a></p>
<p><a class="link"   href="https://xie.infoq.cn/article/3627ea82a8ddfd08e28036f9b" >kafka的实现原理_kafka_八两_InfoQ写作社区<i class="fas fa-external-link-alt"></i></a></p>
<p><a class="link"   href="https://juejin.cn/post/7028149679976251422#heading-8" >SpringBoot整合kafka - 掘金<i class="fas fa-external-link-alt"></i></a></p>
<p><a class="link"   href="https://jiamaoxiang.top/2020/07/06/Kafka%E7%9A%84Controller-Broker%E6%98%AF%E4%BB%80%E4%B9%88/" >Kafka的Controller Broker是什么<i class="fas fa-external-link-alt"></i></a></p>
<p><a class="link"   href="https://my.oschina.net/keking/blog/3056698" >spring boot集成kafka之spring-kafka深入探秘 - 凯京科技的个人空间 - OSCHINA - 中文开源技术交流社区<i class="fas fa-external-link-alt"></i></a></p>
]]></content>
      <tags>
        <tag>kafka</tag>
        <tag>springboot</tag>
        <tag>mq</tag>
        <tag>分布式</tag>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title>29.22分钟学会正则表达式</title>
    <url>/2018/11/22/29-22%E5%88%86%E9%92%9F%E5%AD%A6%E4%BC%9A%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/</url>
    <content><![CDATA[<h2 id="写在最前面"><a href="#写在最前面" class="headerlink" title="写在最前面"></a>写在最前面</h2><p><strong>看到标题你可能会疑惑为什么不是30分钟？</strong><br>因为我这个文章图文并茂，非常恐怖，兄弟，其实你不用30分钟就可以看懂。<br>你可能会以为我在吹牛B，但是当你看完的时候，一掐表，你会发现<br>我真的是在吹牛B<br><strong>那又为什么是.22呢？</strong><br>作为一个理科生，保留两位小数是不变的信仰。<br>而在下，仅仅是喜欢2这个数字，如是而已</p>
<h2 id="正则表达式"><a href="#正则表达式" class="headerlink" title="正则表达式"></a>正则表达式</h2><p>正则表达式，又称规则表达式。（英语：Regular Expression，在代码中常简写为regex、regexp或RE），计算机科学的一个概念。正则表达式通常被用来检索、替换、校验那些符合某个模式(规则)的文本。</p>
<h2 id="RegExp对象"><a href="#RegExp对象" class="headerlink" title="RegExp对象"></a>RegExp对象</h2><p>在爪洼死苦瑞per特中，RegExp 对象表示正则表达式，它是对字符串执行模式匹配的强大工具。<br>那么要如何使用呢？<br>两种方式：<strong>字面量，构造函数</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">var reg = /\bhello\b/g  //字面量 </span><br><span class="line">// \b代表单词边界（WordBoundary） 也就是说这个正则匹配的是 hello world这种hello 而不是helloworld</span><br><span class="line">//因为helloworld连起来了，没有单词边界</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">var reg = new RegExp(&#x27;\\bhello\\b&#x27;,&#x27;g&#x27;)</span><br><span class="line">//注意两者的区别</span><br><span class="line">//后面这种方法需要转义反斜杠（javascript的原因）,</span><br><span class="line">//而且这个g(修饰符,全局匹配)是单独提取出来的</span><br><span class="line">//而且正则两边没有/包围的，上面第一种是这样的=&gt; /正则表达式/</span><br></pre></td></tr></table></figure>

<h2 id="正则可视化工具"><a href="#正则可视化工具" class="headerlink" title="正则可视化工具"></a>正则可视化工具</h2><p><a class="link"   href="https://jex.im/regulex/#!flags=&re=%5E%28a%7Cb%29*?" >Regulex<i class="fas fa-external-link-alt"></i></a><br>可视化图形，对理解正则有非常<strong>大</strong>的帮助<br>二话不说先进来这个网站，这个文章将使用这个网站来验证写的例子。</p>
<h2 id="元字符"><a href="#元字符" class="headerlink" title="元字符"></a>元字符</h2><p>正则表达式由两种基本字符类组成</p>
<ul>
<li>原义字符</li>
<li>元字符</li>
</ul>
<p>原义字符，就是表示原本意思的字符，像上面正则中的hello，就代表匹配hello这个字符串<br>元字符呢，就是表示不是原本意思的字符，这样想就简单多了吧。像上面这个\b</p>
<p><img  
                     lazyload
                     alt="image"
                     data-src="https://i.loli.net/2018/11/22/5bf681a979bb3.png"
                      alt="clipboard.png"
                ></p>
<p><img  
                     lazyload
                     alt="image"
                     data-src="https://i.loli.net/2018/11/22/5bf681a9791ff.png"
                      alt="clipboard.png"
                ></p>
<p><strong>既然元字符表示的不是本身的字符，那我如果就要匹配它原本的字符呢？比如说我就要匹配+号，*号，那么请使用 \ 来转义字符</strong></p>
<p>下面这些元字符先随便过一遍先，不用背熟也可往下看~</p>
<ul>
<li>$ 匹配输入字符串的结尾位置。如果设置了 RegExp 对象的 Multiline 属性，则 $ 也匹配 ‘n’ 或 ‘r’。要匹配 $ 字符本身，请使用 $。</li>
<li>() 标记一个子表达式的开始和结束位置。子表达式可以获取供以后使用。要匹配这些字符，请使用 ( 和 )。</li>
<li>* 匹配前面的子表达式零次或多次。要匹配 * 字符，请使用 *。</li>
<li>+ 匹配前面的子表达式一次或多次。要匹配 + 字符，请使用 +。</li>
<li>. 匹配除换行符 n 之外的任何单字符。要匹配 . ，请使用 . 。</li>
<li>[] 标记一个中括号表达式的开始。要匹配 [，请使用 [。</li>
<li>{} 标记限定符表达式的开始。要匹配 {，请使用 {。</li>
<li>| 指明两项之间的一个选择。要匹配 |，请使用 |。</li>
<li>? 匹配前面的子表达式零次或一次，或指明一个非贪婪限定符。要匹配 ? 字符，请使用 ?。</li>
<li>\ 将下一个字符标记为或特殊字符、或原义字符、或向后引用、或八进制转义符。例如， ‘n’ 匹配字符 ‘n’。’n’ 匹配换行符。序列 ‘&#39; 匹配 “”，而 ‘(‘ 则匹配 “(“。</li>
<li>^ 匹配输入字符串的开始位置，除非在方括号表达式中使用，此时它表示不接受该字符集合。要匹配 ^ 字符本身，请使用 ^。</li>
<li>\cX 匹配由x指明的控制字符。例如， cM 匹配一个 Control-M 或回车符。x 的值必须为 A-Z 或 a-z 之一。否则，将 c 视为一个原义的 ‘c’ 字符。</li>
<li>\f 匹配一个换页符。等价于 x0c 和 cL。</li>
<li>\n 匹配一个换行符。等价于 x0a 和 cJ。</li>
<li>\r 匹配一个回车符。等价于 x0d 和 cM。</li>
<li>\s 匹配任何空白字符，包括空格、制表符、换页符等等。等价于 [ fnrtv]。注意 Unicode 正则表达式会匹配全角空格符。</li>
<li>\S 匹配任何非空白字符。等价于 <a class="link"   href="https://segmentfault.com/a/1190000016964825#fn-1" >1<i class="fas fa-external-link-alt"></i></a>。</li>
<li>\t 匹配一个制表符。等价于 x09 和 cI。</li>
<li>\v 匹配一个垂直制表符。等价于 x0b 和 cK</li>
</ul>
<h2 id="边界"><a href="#边界" class="headerlink" title="边界"></a>边界</h2><p><img  
                     lazyload
                     alt="image"
                     data-src="https://i.loli.net/2018/11/22/5bf681a9792b4.png"
                      alt="clipboard.png"
                ></p>
<p>从一开始的例子我们就知道了这个b,不对，是这个\b<br>他表示的就是单词边界的意思.<br>我们知道，f<em>ck这个是有很多用法的，可以单独用，也可以加个ing多种词性使用。<br>然后我们只想找到单独的f</em>ck,看代码</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">//作为光荣的社会主义接班人怎么可能用f*ck做例子呢?</span><br><span class="line">var reg = /\bis\b/g;</span><br><span class="line">var str = &quot;this is me&quot;;</span><br><span class="line">str.replace(reg,&#x27;X&#x27;)</span><br><span class="line">//&quot;this X me&quot;</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">var reg = /is/g;</span><br><span class="line">var str = &quot;this is me&quot;;</span><br><span class="line">str.replace(reg,&#x27;X&#x27;)</span><br><span class="line">//&quot;thX X me&quot;</span><br></pre></td></tr></table></figure>

<p>两者区别清晰可见，不容我多说了吧，各位客官。</p>
<p>再来看看一个问题，<strong>如果我只要开头部分的A字符而文本中间的A字符却不要，又该如何？</strong><br>只需如此，便可对敌</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">var reg = /^A/g;</span><br><span class="line">var str = &quot;ABA&quot;;</span><br><span class="line">str.replace(reg,&#x27;X&#x27;);</span><br><span class="line">//&quot;XBA&quot;</span><br></pre></td></tr></table></figure>

<p><img  
                     lazyload
                     alt="image"
                     data-src="https://i.loli.net/2018/11/22/5bf682db6f114.png"
                      alt="clipboard.png"
                ></p>
<p>需要以A为结尾的正则，则是如下</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">var reg = /A$/g;</span><br><span class="line">var str = &quot;ABA&quot;;</span><br><span class="line">str.replace(reg,&#x27;X&#x27;);</span><br><span class="line">//&quot;ABX&quot;</span><br></pre></td></tr></table></figure>

<p><img  
                     lazyload
                     alt="image"
                     data-src="https://i.loli.net/2018/11/22/5bf681a9f4213.png"
                      alt="clipboard.png"
                ></p>
<p><strong>注意，正如开头结尾的位置一样，^和$的位置也是如此，^放在正则表达式前面，$放在表达式后面</strong></p>
<h2 id="字符类"><a href="#字符类" class="headerlink" title="字符类"></a>字符类</h2><p>一般情况下，正则表达式一个字符对应字符串的一个字符<br>比如表达式 \bhello 就表示 匹配 字符\b h e l l o，</p>
<p><strong>如果我们想要匹配一类字符的时候?</strong><br>比如我要匹配a或者b或者c，我们就可以使用元字符 []来构建一个简单的类<br>[a,b,c]就把a，b，c归为一类，表示可以匹配a或者b或者c。<br>如果你会一丢丢英文的话，你应该就可以看懂下面的图，one of a，b，c，也就是匹配abc中任意一个~</p>
<p><img  
                     lazyload
                     alt="image"
                     data-src="https://i.loli.net/2018/11/22/5bf681aa3360b.png"
                      alt="clipboard.png"
                ></p>
<h2 id="范围类"><a href="#范围类" class="headerlink" title="范围类"></a>范围类</h2><p>当我们学习了上面的内容以后，如果我们要写匹配0到9的数字，就应该是这样写</p>
<p><img  
                     lazyload
                     alt="image"
                     data-src="https://i.loli.net/2018/11/22/5bf681aabd273.png"
                      alt="clipboard.png"
                ></p>
<p><strong>但是如果我要匹配更多呢？那不是键盘都要敲烂了？这正则也太不智能了吧？？？</strong><br>显然，你能想到的，创造正则的人也想到了<br>我们可以这样子</p>
<p><img  
                     lazyload
                     alt="image"
                     data-src="https://i.loli.net/2018/11/22/5bf681aaed373.png"
                      alt="clipboard.png"
                ></p>
<p>好了，方便了一些，然后你可能又会吃惊，那么我的短横线-呢？我如果要匹配0-9以及短横线呢？<br>莫慌，只要在后面补回去即可<br>这个图可以清楚看到有两条分支，也就是说我可以走0-9这条路也可以走短横线这条路</p>
<p><img  
                     lazyload
                     alt="image"
                     data-src="https://i.loli.net/2018/11/22/5bf681ac4f38a.png"
                      alt="clipboard.png"
                ></p>
<p><img  
                     lazyload
                     alt="image"
                     data-src="https://i.loli.net/2018/11/22/5bf681ac4ea3e.png"
                      alt="clipboard.png"
                ></p>
<h2 id="预定义类"><a href="#预定义类" class="headerlink" title="预定义类"></a>预定义类</h2><p>学习了上面以后，我们就可以书写匹配数字的正则了，[0-9]</p>
<p><strong>那么有没有更简便更短的方法呢？</strong></p>
<p>巧了，正则就是辣么强大</p>
<p>在上面的元字符部分内容中，你可能已经窥得其中精妙了</p>
<p>上表格，不是，上图（这个segmentfault哪里插入表格啊？？）</p>
<p><img  
                     lazyload
                     alt="image"
                     data-src="https://i.loli.net/2018/11/22/5bf6830454dff.png"
                      alt="clipboard.png"
                ></p>
<p><img  
                     lazyload
                     alt="image"
                     data-src="https://i.loli.net/2018/11/22/5bf68303e4577.png"
                      alt="clipboard.png"
                ></p>
<p><img  
                     lazyload
                     alt="image"
                     data-src="https://i.loli.net/2018/11/22/5bf68307699ef.png"
                      alt="clipboard.png"
                ></p>
<p><img  
                     lazyload
                     alt="image"
                     data-src="https://i.loli.net/2018/11/22/5bf68307819c3.png"
                      alt="clipboard.png"
                ></p>
<p><img  
                     lazyload
                     alt="image"
                     data-src="https://i.loli.net/2018/11/22/5bf68307aa177.png"
                      alt="clipboard.png"
                ></p>
<p>我们可以根据英文单词的意思，来记住这些预定义类的用法。<br><strong>我们发现，大写字母和小写字母的区别就是取反!，如d和D</strong><br>同时我们从表格中的等价类可以发现如果我们要一个类的取反，那么就在类中加一个 <strong>^</strong><br><strong>none of abc</strong></p>
<p><img  
                     lazyload
                     alt="image"
                     data-src="https://i.loli.net/2018/11/22/5bf68307ee314.png"
                      alt="clipboard.png"
                ></p>
<h2 id="量词"><a href="#量词" class="headerlink" title="量词"></a>量词</h2><p><strong>如果要你写一个匹配10个数字的正则？你会怎么写</strong><br>诶~你可能已经胸有成竹的写下了</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">\d\d\d\d\d\d\d\d\d\d</span><br></pre></td></tr></table></figure>

<p>吃惊，你会发现，尽管是你单身二十余年的右手，依然感到了一丝乏力！<br><strong>疲惫，有时是在过度劳累之后</strong><br>为了挽救一些人的右臂，正则有了量词<br>实现上面的需求我们只要 \d{10}<br><img  
                     lazyload
                     alt="image"
                     data-src="https://i.loli.net/2018/11/22/5bf683097bd98.png"
                      alt="clipboard.png"
                ></p>
<p><strong>Digit 10times</strong><br>为了方便一些英语不好的人，比如我，我甚至使用了鲜为人知的百度翻译（广告费私我）</p>
<p><img  
                     lazyload
                     alt="image"
                     data-src="https://i.loli.net/2018/11/22/5bf6830e1bdbe.png"
                      alt="clipboard.png"
                ></p>
<p><strong>但是，如果我不知道要匹配具体多少个数字呢？反正就是匹配100个到1000个之间的数字</strong><br>当当当当~</p>
<p><img  
                     lazyload
                     alt="image"
                     data-src="https://i.loli.net/2018/11/22/5bf6830dcc9ef.png"
                      alt="clipboard.png"
                ></p>
<p>让我们看看可视化工具的结果，方便理解</p>
<p><strong>注意，这个{n,m}是包括n次和m次的哦，是闭区间哦</strong></p>
<p><img  
                     lazyload
                     alt="image"
                     data-src="https://i.loli.net/2018/11/22/5bf6830ece695.png"
                      alt="clipboard.png"
                ></p>
<h2 id="贪婪模式与非贪婪模式"><a href="#贪婪模式与非贪婪模式" class="headerlink" title="贪婪模式与非贪婪模式"></a>贪婪模式与非贪婪模式</h2><p>从上面一则我们知道，如果我们要匹配100到1000个数字的话，是这样写<br>\d{100,1000}<br><strong>如果我给的字符串里有1000个数字，但是我只想匹配前面100个呢？</strong></p>
<p>如果按照上面这样写，则如下</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">var reg = /\d&#123;3,6&#125;/;</span><br><span class="line">var str = &quot;123456789&quot;;</span><br><span class="line">str.replace(reg,&#x27;替换成这个&#x27;);</span><br><span class="line">//&quot;替换成这个789&quot;</span><br></pre></td></tr></table></figure>

<p>我们可以看到，上面这个例子是匹配了6个数字，将6个数字替换了，尽管他的正则匹配的是3到6个数字。</p>
<p><strong>没错，它是贪婪的！它会尽可能地匹配更多！</strong><br>这就是正则的 贪婪匹配，这是默认的，如果我们不想要那么贪婪，如何变得容易满足一点？<br><strong>只需要在量词后面加上 ? 即可</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">var reg = /\d&#123;3,6&#125;?/;</span><br><span class="line">var str = &quot;123456789&quot;;</span><br><span class="line">str.replace(reg,&#x27;替换成这个&#x27;);</span><br><span class="line">//&quot;替换成这个456789&quot;</span><br></pre></td></tr></table></figure>

<p>可以清楚看到正则只匹配了前面3个数字~这就是正则的非贪婪模式</p>
<h2 id="分支条件"><a href="#分支条件" class="headerlink" title="分支条件"></a>分支条件</h2><p>如果我只需要匹配100个或者1000个数字呢？<br>就只有100和1000两种可能，而不是100到1000任意一个数字，又该如何对敌？<br>这就要设计到正则的分支条件了</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">\d&#123;100&#125;|\d&#123;1000&#125;</span><br></pre></td></tr></table></figure>

<p><img  
                     lazyload
                     alt="image"
                     data-src="https://i.loli.net/2018/11/22/5bf683b8ec145.png"
                      alt="clipboard.png"
                ></p>
<p>需要注意的是这个 | 分割的是左右两边所有部分，而不是仅仅连着这个符号的左右两部分，看下图</p>
<p><img  
                     lazyload
                     alt="image"
                     data-src="https://i.loli.net/2018/11/22/5bf683ba2887a.png"
                      alt="clipboard.png"
                ></p>
<p>有时候我们只需要一部分是分支，后面走的是同一条主干，只需要把分支用()包含即可</p>
<p><img  
                     lazyload
                     alt="image"
                     data-src="https://i.loli.net/2018/11/22/5bf683bb24e22.png"
                      alt="clipboard.png"
                ></p>
<p><strong>注意：这个匹配是从正则左边的分支条件开始的，如果左边满足了，那么右边就不会在对比！</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">var reg = /\d&#123;4&#125;|\d&#123;2&#125;/</span><br><span class="line">var str = &quot;12345&quot;</span><br><span class="line">str.replace(reg,&#x27;X&#x27;);</span><br><span class="line">// &quot;X5&quot;</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">var reg = /\d&#123;2&#125;|\d&#123;4&#125;/</span><br><span class="line">var str = &quot;12345&quot;</span><br><span class="line">str.replace(reg,&#x27;X&#x27;);</span><br><span class="line">//&quot;X345&quot;</span><br></pre></td></tr></table></figure>

<h2 id="前瞻-x2F-后顾"><a href="#前瞻-x2F-后顾" class="headerlink" title="前瞻&#x2F;后顾"></a>前瞻&#x2F;后顾</h2><p>sometimes，我们要找寻的字符可能还要依靠前后字符来确定<br><strong>比如说我要替换连续的2个数字，而且它的前面要连着是2个英文字母，这样的数字我才要</strong><br>你可能会疑惑,这样写不就完事了吗？</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">\d&#123;2&#125;\w&#123;2&#125;</span><br></pre></td></tr></table></figure>

<p><strong>上面匹配的是2个数字和2个字母，虽然是连着的，但是匹配了是4个字符，如果我要替换匹配文本的话，那就替换了4个字符，而我们只想替换2个数字！</strong><br>这个时候就需要用到断言了<br>首先我们需要明白几个点</p>
<ul>
<li>正则表达式从文本头部到尾部开始解析，文本尾部方向叫做‘前’，也就是往前走，就是往尾巴走</li>
<li><strong>前瞻</strong>就是正则表达式匹配到规则（此例中的‘2个数字’）的时候，向前看看，看看是否符合断言（此例中的‘前面连着2个字母’），后瞻&#x2F;后顾的规则则相反。（javascript不支持后顾）</li>
</ul>
<p>上表格！</p>
<p><img  
                     lazyload
                     alt="image"
                     data-src="https://i.loli.net/2018/11/22/5bf683bb4acfb.png"
                      alt="clipboard.png"
                ></p>
<p>根据表格内容，我们就可以解决这个问题了，注意\w包括数字哦~题目要求是连着2个字母</p>
<p><img  
                     lazyload
                     alt="image"
                     data-src="https://i.loli.net/2018/11/22/5bf68485c0021.png"
                      alt="clipboard.png"
                ></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">var reg = /\d&#123;2&#125;(?=[a-zA-Z]&#123;2&#125;)/;</span><br><span class="line">var str = &quot;1a23bc456def&quot;;</span><br><span class="line">str.replace(reg,&#x27;X&#x27;);</span><br><span class="line">//&quot;1aXbc456def&quot;</span><br></pre></td></tr></table></figure>

<p><strong>只替换了数字，没有替换后面的断言哦！</strong></p>
<p>顺便把这个负向前瞻看看吧</p>
<p><img  
                     lazyload
                     alt="image"
                     data-src="https://i.loli.net/2018/11/22/5bf683bc30240.png"
                      alt="clipboard.png"
                ></p>
<p>看到这个<strong>not</strong> followed by 我想你应该知晓用法了</p>
<h2 id="分组"><a href="#分组" class="headerlink" title="分组"></a>分组</h2><p><strong>当我们要匹配一个出现三次的单词而不是数字的时候，会怎么写呢？</strong><br>你可能会这样写</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">hello&#123;3&#125;</span><br></pre></td></tr></table></figure>

<p>然后你打开可视化工具</p>
<p><img  
                     lazyload
                     alt="image"
                     data-src="https://i.loli.net/2018/11/22/5bf683bc2e857.png"
                      alt="clipboard.png"
                ></p>
<p>妈耶，居然只重复了我的o字母！死渣则，好过分</p>
<p><strong>其实，我们只要使用（）就可以达到分组的目的，使量词作用于分组，上面分支条件中的括号亦是如此</strong></p>
<p><img  
                     lazyload
                     alt="image"
                     data-src="https://i.loli.net/2018/11/22/5bf683bd1f493.png"
                      alt="clipboard.png"
                ></p>
<p>分组以后怎么使用分组内容呢？<br>首先看一个问题，<strong>如何匹配8个不连续的数字？</strong><br>如果你不使用分组，你会发现根本无从下手，因为你不能判断出有无重复！<br>我们先公布答案，再来分析一波</p>
<p><img  
                     lazyload
                     alt="image"
                     data-src="https://i.loli.net/2018/11/22/5bf683c04a93a.png"
                      alt="clipboard.png"
                ></p>
<ul>
<li>首先，这个(?!负向前瞻断言A)表达式B，这里使用的是负向前瞻，也就是说断言A前面的内容（表达式B），不能符合表达式A，这个说法很拗口，我嘴巴都拗不过来了。能听明白吧，这个设计就是，我这个断言是“出现重复的数字”，然后表达式是“8个数字”，<strong>”8个数字“不能复合“出现重复的数字”</strong></li>
<li>然后，这个 .<em>(\d).</em> 呢，是先找到一个在任意位置出现的数字，为什么是任意位置呢？因为我们判断的重复可能出现在任何位置；看上面的可视化也就可以明白，<strong>\d前后有0-n个字符,所以说他是任意位置的</strong>。</li>
<li>最关键的来了，这个\1代表什么呢？仔细看你可以发现，\d加了一个括号，这个括号就代表着<strong>分组</strong>，那么是几号分组呢？第一个括号就是分组1（默认情况下），如果还有第二个括号，那就是分组2，<strong>前瞻的括号是不算的噢</strong>，而这个\1呢就代表着引用这个分组1，使用\2引用分组2。你也许会好奇，我引用它是相当于在这个位置写了一个\d吗？NOP，不仅仅这么简单，<strong>它引用的是这个\d的内容，也就是说他会和\d是一样的值！这不就是重复了吗？！！！</strong>这个 .<em>(\d).<em>\1 就代表着**任意位置出现了任意次数的重复</em></em></li>
<li>最后，我们把这些整合在一起就是，<strong>匹配8个数字不能出现任意的重复</strong>。(?!出现任意重复)8个数字，因为这个(?!)是负向前瞻，所以。。。emmm。。这样就理解了吧。</li>
</ul>
<p>分组还有其他更详细的内容，但是篇幅有限，<strong>马上就到30分钟了</strong>。只好捡一些有价值常用的讲了~</p>
<h2 id="嘿嘿嘿"><a href="#嘿嘿嘿" class="headerlink" title="嘿嘿嘿"></a>嘿嘿嘿</h2><p>正则就介绍到这里啦~</p>
]]></content>
  </entry>
  <entry>
    <title>不小心提交到Git远程仓库的文件，怎么完全从仓库中清除?</title>
    <url>/2022/12/22/%E4%B8%8D%E5%B0%8F%E5%BF%83%E6%8F%90%E4%BA%A4%E5%88%B0%20Git%20%E7%9A%84%E6%96%87%E4%BB%B6%EF%BC%8C%E6%80%8E%E4%B9%88%E5%AE%8C%E5%85%A8%E4%BB%8E%E4%BB%93%E5%BA%93%E4%B8%AD%E6%B8%85%E9%99%A4/</url>
    <content><![CDATA[<p>使用 Git 做代码版本控制时，有时候会不小心把某些敏感的文件提交到 Git 仓库，可能过后很久才发现。或者是以前提交的文件，现在发现不合适，需要从仓库中清理。 如果但是删除文件，然后提交的话，还是可以从仓库的历史记录中找出这个文件，这个问题就比较严重了。</p>
<p>所以，如果要彻底从 Git 仓库中删除某个文件可以用如下操作：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git filter-branch --index-filter &#x27;git rm -rf --cached --ignore-unmatch path_to_file&#x27; HEAD</span><br></pre></td></tr></table></figure>

<p>其中 <code>path_to_file</code> 就是你要删除的文件在项目中的相对路径，例如：src&#x2F;main&#x2F;resource&#x2F;application.yml 。</p>
<p>执行此命令后，git 会遍历整个仓库的历史记录找出这个文件，清理，然后重新构造 git 的历史链条。</p>
<p>接下来强推就行了<code>git push -f</code>，这样远程仓库上也不会再存在这个文件了。</p>
<blockquote>
<p>本文章转载于OSCHINA用户红薯：<a class="link"   href="https://my.oschina.net/javayou/blog/5497254" >不小心提交到 Git 的敏感文件，怎么完全从仓库中清除 - Java自由人 - OSCHINA - 中文开源技术交流社区<i class="fas fa-external-link-alt"></i></a></p>
</blockquote>
]]></content>
      <tags>
        <tag>Git</tag>
        <tag>远程仓库</tag>
      </tags>
  </entry>
  <entry>
    <title>QQ邮箱如何绑定自己的域名，制作自己的独特邮箱！</title>
    <url>/2018/09/07/QQ%E9%82%AE%E7%AE%B1%E5%A6%82%E4%BD%95%E7%BB%91%E5%AE%9A%E8%87%AA%E5%B7%B1%E7%9A%84%E5%9F%9F%E5%90%8D%EF%BC%8C%E5%88%B6%E4%BD%9C%E8%87%AA%E5%B7%B1%E7%9A%84%E7%8B%AC%E7%89%B9%E9%82%AE%E7%AE%B1%EF%BC%81/</url>
    <content><![CDATA[<p>​    今天下午无聊，北京的天气今天清爽了下来，洗个澡坐到了电脑前，一个QQ消息过来。哦~ 我朋友他们公司注册了一个域名，想问我怎么自定义自己的公司的域名，看着更有专业性呢? 碰巧，也今天下午闲下来了。就直接跟他说拉~ 下面看下这个教程说不定对你有帮助哦~</p>
<p>​     闲话不多说，我们开始吧！</p>
<p>​     首先第一步，先进去QQ邮箱为我们提供专业的域名邮箱入口。(这里注意一点:<strong>登陆的账号建议就是你之后管理这个域名的账号</strong>) ，进去之后直接点创建域名邮箱</p>
<p>​      <a class="link"   href="http://domain.mail.qq.com/" >点我<i class="fas fa-external-link-alt"></i></a></p>
<p>​     第二步: 进去之后，他会根据傻瓜式操作的告诉你，下一步怎么办。现在我们需要做的就是，填写上你的域名(<strong>注意必须要有操作的权限，后期需要绑定解析</strong> )</p>
<p><img  
                     lazyload
                     alt="image"
                     data-src="https://i.loli.net/2019/07/02/5d1b279ec3d1525958.jpg"
                     
                ></p>
<p>​     第三步: 选择你的域名归属，这里直接点其他吧</p>
<p>​      <img  
                     lazyload
                     alt="image"
                     data-src="https://i.loli.net/2019/07/02/5d1b279f3155a96169.jpg"
                     
                ></p>
<p>​      第四步: 直接进去验证域名所有权，然后解析到腾讯的服务器上。</p>
<p><img  
                     lazyload
                     alt="image"
                     data-src="https://i.loli.net/2019/07/02/5d1b279f4d2ab16815.jpg"
                     
                ></p>
<p>这里就需要进去你的云计算的控制面板了，这里腾讯云为例。</p>
<p><img  
                     lazyload
                     alt="image"
                     data-src="https://i.loli.net/2019/07/02/5d1b279f13c0317762.jpg"
                     
                ></p>
<p>当然了，第一个也就是cname的记录了，注意下第二个我们选择 mx记录</p>
<p>随后操作完之后，域名验证好了，现在就可以直接进入账号的控制面板了。</p>
<p><img  
                     lazyload
                     alt="image"
                     data-src="https://i.loli.net/2019/07/02/5d1b279eeaf5796816.jpg"
                     
                ></p>
<p><img  
                     lazyload
                     alt="image"
                     data-src="https://i.loli.net/2019/07/02/5d1b279e9041d58211.jpg"
                     
                ></p>
<p>  第五步:然后我们就可以管理了，点击管理进入这个页面</p>
<p><img  
                     lazyload
                     alt="image"
                     data-src="https://i.loli.net/2019/07/02/5d1b279f40c4219462.jpg"
                     
                ></p>
<p>  <img  
                     lazyload
                     alt="image"
                     data-src="https://i.loli.net/2019/07/02/5d1b279ed6b8244796.jpg"
                     
                ></p>
<p>好了，设置完了，到这里就好啦。赶紧去叫你的朋友发个邮件帮你看看吧~</p>
<p>有什么问题不懂的，可以练习我哦</p>
]]></content>
      <tags>
        <tag>技术</tag>
      </tags>
  </entry>
  <entry>
    <title>免费CDN jsDelivr使用</title>
    <url>/2022/11/14/%E5%85%8D%E8%B4%B9CDN-jsDelivr%E4%BD%BF%E7%94%A8/</url>
    <content><![CDATA[<h1 id="jsDelivr是什么？"><a href="#jsDelivr是什么？" class="headerlink" title="jsDelivr是什么？"></a>jsDelivr是什么？</h1><p>jsDelivr是一种特殊的CDN。 它旨在让用户下载npm和Github上托管JavaScript库。 (如果它们托管在Wordpress.org上，则还可以加载Wordpress插件)。也就是说它可以镜像以下服务</p>
<ol>
<li>wordpress的插件、模板</li>
<li>GitHub开放仓库</li>
<li>NPM公共镜像仓库加速</li>
</ol>
<p>也就是说，我们可以不再自建或自维护CDN！你是NPM的包，它可以同步后为你分发到全球的各个CDN高速节点。你是Github仓库同样也可以使用全球的CDN静态加速。即使你是wordpress的站长，你还可以用它来同步你所使用的模板、插件等。不再需要维护CDN，我们只需要在以上平台上发布，jsDelivr会自动镜像并且分发。</p>
<h2 id="简单demo"><a href="#简单demo" class="headerlink" title="简单demo"></a>简单demo</h2><figure class="highlight html"><table><tr><td class="code"><pre><span class="line">https://cdn.jsdelivr.net/gh/a2501521908/jsdelivr-cdn@1.0/getlanguage.js</span><br></pre></td></tr></table></figure>

<p>我在GitHub上发布了一个仓库<code>jsdelivr-cdn</code>，并且创建了一个版本为<code>1.0</code>，我只需要根据路径取出我所需要的文件即可</p>
<h1 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h1><p>应用中暂时不演示其他，只演示GitHub镜像CDN的使用，别的均是换汤不换药，使用官方规定的网络路径访问即可</p>
<h2 id="Github"><a href="#Github" class="headerlink" title="Github"></a>Github</h2><h3 id="规则"><a href="#规则" class="headerlink" title="规则"></a>规则</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">https://cdn.jsdelivr.net/gh/github用户名/仓库名@版本号/文件路径</span><br></pre></td></tr></table></figure>

<h3 id="0-准备工作"><a href="#0-准备工作" class="headerlink" title="0.准备工作"></a>0.准备工作</h3><blockquote>
<p>分支不限，核心原理就是创建一个仓库的release版本，然后jsDriver会同步你的创建的release版本</p>
</blockquote>
<ol>
<li>先在Github上创建一个公开的仓库</li>
<li>使用Git推送至相关分支仓库的代码,也就是你要使用CDN加速的代码</li>
</ol>
<h3 id="1-创建仓库的Release"><a href="#1-创建仓库的Release" class="headerlink" title="1.创建仓库的Release"></a>1.创建仓库的Release</h3><ol>
<li>点击<code>Create new release</code></li>
</ol>
<p><img  
                     lazyload
                     alt="image"
                     data-src="https://s2.loli.net/2022/11/14/PdxrSsXgiovFRAz.png"
                      alt="去创建版本"
                ></p>
<h3 id="2-填写版本号"><a href="#2-填写版本号" class="headerlink" title="2.填写版本号"></a>2.填写版本号</h3><ul>
<li><code>tag</code>如果不理解在这里可以理解为版本号</li>
<li><code>target</code>是你这个<code>tag</code>需要引用的分支，选择你需要引用的分支，我这里直接选择了<code>main</code></li>
<li>点击 <code>new create tag</code>即可</li>
<li>确认都没问题了，我们选择最下面的<code>Publish release</code>，创建完成版本即可</li>
</ul>
<p><img  
                     lazyload
                     alt="image"
                     data-src="https://s2.loli.net/2022/11/14/bikrYUVQn2ma73K.png"
                      alt="创建版本"
                ></p>
<h3 id="3-测试和应用"><a href="#3-测试和应用" class="headerlink" title="3.测试和应用"></a>3.测试和应用</h3><ul>
<li>原版本    <a class="link"   href="https://cdn.jsdelivr.net/gh/a2501521908/jsdelivr-cdn@1.0/getlanguage.js" >https://cdn.jsdelivr.net/gh/a2501521908/jsdelivr-cdn@1.0/getlanguage.js<i class="fas fa-external-link-alt"></i></a></li>
<li>压缩版本 <a class="link"   href="https://cdn.jsdelivr.net/gh/a2501521908/jsdelivr-cdn@1.0/getlanguage.min.js" >https://cdn.jsdelivr.net/gh/a2501521908/jsdelivr-cdn@1.0/getlanguage.min.js<i class="fas fa-external-link-alt"></i></a></li>
</ul>
<h2 id="WordPress"><a href="#WordPress" class="headerlink" title="WordPress"></a>WordPress</h2><p>从 WordPress.org 插件 SVN 存储库加载任何插件：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">https://cdn.jsdelivr.net/wp/plugins/project/tags/version/file</span><br></pre></td></tr></table></figure>

<p>加载文件的确切版本：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">https://cdn.jsdelivr.net/wp/plugins/wp-slimstat/tags/4.6.5/wp-slimstat.js</span><br></pre></td></tr></table></figure>

<p>加载最新版本（不推荐用于生产用途）：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">https://cdn.jsdelivr.net/wp/plugins/wp-slimstat/trunk/wp-slimstat.js</span><br></pre></td></tr></table></figure>

<p>请求最新版本是危险的，因为新版本可能会带来重大更改。</p>
<p>从 WordPress.org 主题 SVN 存储库加载任何主题：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">https://cdn.jsdelivr.net/wp/themes/project/version/file</span><br></pre></td></tr></table></figure>

<p>加载文件的确切版本：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">https://cdn.jsdelivr.net/wp/themes/twenty-eightteen/1.7/assets/js/html5.js</span><br></pre></td></tr></table></figure>

<p>将“.min”添加到任何 JS&#x2F;CSS 文件以获得缩小版本 - 如果不存在，我们将为您生成它。所有生成的文件都带有源映射，可以在开发过程中轻松使用：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">https://cdn.jsdelivr.net/wp/themes/twenty-eightteen/1.7/assets/js/html5.min.js</span><br></pre></td></tr></table></figure>

<h2 id="NPM"><a href="#NPM" class="headerlink" title="NPM"></a>NPM</h2><p>发布至官方NPM仓库即可</p>
<p>官方提供的访问路径格式为: <code>https://cdn.jsdelivr.net/npm/包名@版本号/目录</code></p>
]]></content>
      <tags>
        <tag>cdn</tag>
        <tag>jsDelivr</tag>
      </tags>
  </entry>
  <entry>
    <title>个人主页折腾记</title>
    <url>/2019/06/07/%E4%B8%AA%E4%BA%BA%E4%B8%BB%E9%A1%B5%E6%8A%98%E8%85%BE%E8%AE%B0/</url>
    <content><![CDATA[<p>活跃一下,不然可能以为我sei了！</p>
<p>端午节在家无聊,所以把之前的个人主页更新了一下,毕竟这是我的第一个域名也是我的第一个网站,怀念当年的感觉也很喜欢那时候的感觉,所以决定更新一手！</p>
<p>话不多说,先上图！</p>
<p>(开局一张图,故事全靠编)</p>
<h2 id="网站图片"><a href="#网站图片" class="headerlink" title="网站图片"></a>网站图片</h2><h3 id="首页："><a href="#首页：" class="headerlink" title="首页："></a>首页：</h3><p><img  
                     lazyload
                     alt="image"
                     data-src="https://i.loli.net/2019/06/08/5cfb75517e1b198840.png"
                      alt="首页图"
                ></p>
<h3 id="关于我"><a href="#关于我" class="headerlink" title="关于我"></a>关于我</h3><p><img  
                     lazyload
                     alt="image"
                     data-src="https://i.loli.net/2019/06/08/5cfb75a57bb7b49629.png"
                      alt="关于我"
                ></p>
<h2 id="网站的小功能List"><a href="#网站的小功能List" class="headerlink" title="网站的小功能List:"></a>网站的小功能List:</h2><p>1：依旧存在 中英繁 国际化页面</p>
<p>2：增加一言： 一些可以鼓励自己的心灵鸡汤之类的</p>
<p>3：更简洁大气的页面</p>
<p>4：增加邮件联系的方式</p>
<p>这个网站是我很喜欢的一个网站,并且我有精力就努力的维护下去,很有纪念意义！</p>
<p>———————–中场抱怨一手————————-</p>
<p>嗯今天看了好多朋友的网站,发现有的可能已经宕机，有的做的越来越帅,也发现了很多人已经停更。可能都来不及说一声再见把！</p>
<p>———————–中场抱怨结束————————-</p>
<p>更新之后的设计使用了现在很流行的弧形UI，配色使用了贵族很喜欢用的紫色！嗯 自我感觉良好</p>
<h2 id="关于源代码"><a href="#关于源代码" class="headerlink" title="关于源代码:"></a>关于源代码:</h2><p>我在挂别的地方测试的时候就已经很多小伙伴找我要了,反正静态的网站,很喜欢我们就一起用 hhh</p>
<p>全球最大的同性交友网站链接奉上:</p>
<p><a class="link"   href="https://github.com/a2501521908/homedemo" >https://github.com/a2501521908/homedemo<i class="fas fa-external-link-alt"></i></a></p>
<p>嗯！ 最后祝各位老朋友:</p>
<p>天天快乐，幸福安康。</p>
]]></content>
      <tags>
        <tag>技术</tag>
      </tags>
  </entry>
  <entry>
    <title>关于停止使用 957xx.cc域名</title>
    <url>/2022/11/29/%E5%85%B3%E4%BA%8E%E5%81%9C%E6%AD%A2%E4%BD%BF%E7%94%A8%20957xx.cc%E5%9F%9F%E5%90%8D/</url>
    <content><![CDATA[<h1 id="关于停止使用-957xx-cc域名"><a href="#关于停止使用-957xx-cc域名" class="headerlink" title="关于停止使用 957xx.cc域名"></a>关于停止使用 957xx.cc域名</h1><h2 id="详情"><a href="#详情" class="headerlink" title="详情"></a>详情</h2><p>因原域名到期并且备案被撤销，所以转向新的域名。即：<code>52xk.cc</code>，寓意为：我爱小轲，新的域名更好记更简单，是本人珍藏了很久的一个域名，最近终于得以机会使用</p>
<p>同时，域名邮箱也进行了下架，幸好没使用老域名邮箱注册什么平台，不然换绑也够头疼喽！</p>
<h2 id="收到网站备案IP整改通知解决方案"><a href="#收到网站备案IP整改通知解决方案" class="headerlink" title="收到网站备案IP整改通知解决方案"></a>收到网站备案IP整改通知解决方案</h2><p>同时在这里给大家说一下，如果云计算厂商主动联系你，并且说你的解析IP与备案IP不一致，要求你将域名解析IP修改为与备案IP一致或者提交变更备案将域名IP修改为域名实际解析IP，本人是如何解决的</p>
<p>很多朋友可能都是备案后原云主机会被回收，IP自然也不存在无法找回了，变更又得提交一大堆程序并且还得买云服务器！如果遇到此情况还请你不要惊慌，在今天（2022-11-29）目前还是可以使用云计算厂商的CDN产品，CDN再转发到你现有源站即可。</p>
<p>如果客服的态度很严格，那你依旧有权利要求客服去找他的上级沟通，最终达成一致。</p>
]]></content>
      <tags>
        <tag>通知</tag>
        <tag>暂停</tag>
      </tags>
  </entry>
  <entry>
    <title>半年了，你的梦想又去了哪里?</title>
    <url>/2018/08/10/%E5%8D%8A%E5%B9%B4%E4%BA%86%EF%BC%8C%E4%BD%A0%E7%9A%84%E6%A2%A6%E6%83%B3%E5%8F%88%E5%8E%BB%E4%BA%86%E5%93%AA%E9%87%8C/</url>
    <content><![CDATA[<p>  不知不觉，半年时间已经过去了。时光如梭，怎么样? 你的梦想呢? 是不是更远了一步?</p>
<p><img  
                     lazyload
                     alt="image"
                     data-src="https://i.loli.net/2019/07/02/5d1b268f2843120335.jpg"
                     
                ></p>
<p>​     昨天无意间，无意间看到了以前的小米手机(红  红 红..红米)手机还是以前上高中上面的照片，看到了以前跟同学们的一些合照，想到了上一年同学聚会的场面，谁谁谁都变了许多呀。哎呀，你看看我，想到了这些就又开始怀旧了起来，不知不觉的，时间总是不等人。总是感觉还有时间，可是回头才发现，真的是不珍惜 什么都没有了。</p>
<p>​    正当还犯牢骚的时候，忽然想看看春节还有多长时间，似乎出来这么长时间总是感觉时间过的很快。结果一百度，瞬间吓蒙了。自己似乎都不知道过年实在几月，还有多长时间。还得自己百度。</p>
<p>​    回忆半年前的那些在一块玩耍，放炮的照片，再看看外面北京这个大城市的蓝天白云，楼下的车辆一辆又一辆的过。光阴似箭，离开村子也半年了。</p>
<p>​    然而，我思想还是我刚刚走进社会。还是一个吚吖学语的幼儿，还是一个不谙人世的少年，还是一个刚刚立志的青年。我就应学习东西的才刚刚尝到一滴甘露，应对知识的海洋，我才初涉小溪，刚刚湿脚；应对社会这个大学校，我才刚刚进门，刚刚看到科学的殿堂，才刚刚听到最基础的ABC、AOE；应对人生这道考题，我才刚刚思考，刚刚有了一点初浅的认识，刚刚看到前进的方向，刚刚看到一丝追求目标的亮光…… </p>
<p>​    但是，这一切容不得你思考，容不得你学习，容不得你偿试，容不得你练习、演习，岁月却已经催人老了，你的人生却已走过少年、青年,转眼间已经走过五分之一了。</p>
<p>​    或许人生就是这样，也许人也是这样，总是在不知道珍惜的时候，总以为时间和她(他)都还在，却或过头来，我们都已经分道扬镳了。没办法，眼下只能好好的使劲拼呀,加油 朋友们。</p>
<p>​    </p>
]]></content>
  </entry>
  <entry>
    <title>新的一年,HI!</title>
    <url>/2019/02/12/%E6%96%B0%E7%9A%84%E4%B8%80%E5%B9%B4-HI/</url>
    <content><![CDATA[<p>  转眼已经2019了,时间过的可是真快,生活还是那么的苟且，坐在即将出发的路上给自己来一个晚来的新年文章。</p>
<h3 id="先给自己来一个简单的2018的年总结吧"><a href="#先给自己来一个简单的2018的年总结吧" class="headerlink" title="先给自己来一个简单的2018的年总结吧:"></a>先给自己来一个简单的2018的年总结吧:</h3><h5 id="1：博客折腾折腾我还是到了hexo-并且越来越懒了…"><a href="#1：博客折腾折腾我还是到了hexo-并且越来越懒了…" class="headerlink" title="1：博客折腾折腾我还是到了hexo,并且越来越懒了…"></a>1：博客折腾折腾我还是到了hexo,并且越来越懒了…</h5><p>​           2018年夏天左右,服务器到期了现在我一个穷鬼想了想还是不要弄服务器的了,毕竟来回都是RMB，能少点阿里就少点吧,还可以学习一点新的东西</p>
<h5 id="2：来到了我现在的学校-努力的学习-放下了一切的杂念-以后我想也不会了"><a href="#2：来到了我现在的学校-努力的学习-放下了一切的杂念-以后我想也不会了" class="headerlink" title="2：来到了我现在的学校,努力的学习,放下了一切的杂念(以后我想也不会了)"></a>2：来到了我现在的学校,努力的学习,放下了一切的杂念(以后我想也不会了)</h5><p>​           还是清楚的记得去年的我狂妄自大的去做一些事情，结果在3月份出来去<a class="link"   href="https://baike.baidu.com/item/%E5%AE%BF%E8%BF%81/" >宿迁<i class="fas fa-external-link-alt"></i></a>看一个学校的时候，试听期间就感觉到了这里大佬云集,甚至说的东西我都还有点听不懂,才知道自己的三斤八两,不过也还是把自己的性子磨了磨，但是也有一些原因来到了我现在的学校。</p>
<h5 id="3-年底了学校给了15天的假期回家-给自己动了个小小的手术-emm"><a href="#3-年底了学校给了15天的假期回家-给自己动了个小小的手术-emm" class="headerlink" title="3:   年底了学校给了15天的假期回家,给自己动了个小小的手术,emm"></a>3:   年底了学校给了15天的假期回家,给自己动了个小小的手术,emm</h5><p>​         今年回家回来,不知道是我真的点背还是怎么,脚的指甲老是去肉里探索(瞬间心里wc)，一想到始终还是得做,毕竟到时候上班回来的话时间可能会更少,就去了医院做了这个小小的手术。</p>
<p>​         当然了,这个年假是我目前活这么长最无聊的年假,真真正正的躺了15天,在上车的前两个小时,抓紧回来更新了这个文章,希望自己以后可以幸运点.</p>
<p>​        不过时间没有白白浪费掉还好,我和我的小组一起趁着年假，做了一个小小的项目,也学会了很多的业务逻辑</p>
<p>  哈哈哈，看到这里可能：？？？ 黑人问号，你到底在干了什么</p>
<h3 id="现在在学习的一些东西"><a href="#现在在学习的一些东西" class="headerlink" title="现在在学习的一些东西:"></a>现在在学习的一些东西:</h3><p>​     1:首要的就是把自己眼前的java学好,以及深入java web开发</p>
<p>​     2:学习一些框架,自学一些语言等</p>
<p>​     3:以及一些大数据时代一个bug触发机必须掌握的东西</p>
<p>  嗯,可能大神看到了这个微微一笑,没错我确实好菜,希望到时候大佬带带我~</p>
<p><strong>EMMMMMMMMM—————–这可能是最心情复杂的文章</strong></p>
<p>为什么这么说呢？因为在写上面的时候我还在不慌不忙的写，结果直接告诉我，高速封路了…….</p>
<p><img  
                     lazyload
                     alt="image"
                     data-src="https://i.loli.net/2019/07/02/5d1b252c772a827336.jpg"
                     
                ></p>
<p>赶紧合起来电脑就去高铁站,就想着期待有一张我的票,慌慌张张的emm,想着只要是别误了我上课怎么都行,售票员小哥哥跟我说,高铁没了就剩下一张站着的火车票,瞬间运气爆棚 站着上了火车。</p>
<p>当我走到石家庄的时候,有一个人可能是坐累了,叫了我一下他就抱着孩子去卧铺那边了,真的是遇到贵人了,在火车上都不敢睡觉,生怕人家回来了人家站着我在哪坐着,EMMMM</p>
<p>就这样到了北京站直接就回来了，2点多,被这场封高速已经弄得绝望了。</p>
<h3 id="扯这么多-给自己的2019立一个flag吧！"><a href="#扯这么多-给自己的2019立一个flag吧！" class="headerlink" title="扯这么多,给自己的2019立一个flag吧！"></a><strong><strong>扯这么多,给自己的2019立一个flag吧！</strong></strong></h3><p>1.在北京实习找到一份稳定的饭碗。</p>
<p>2.去一次旅游(见一个人)  不知道能不能</p>
<p>3.希望在年底学会开车 哈哈~~</p>
<p>嘿嘿,给大家一声晚来的新年快乐！</p>
<p>​     </p>
]]></content>
      <tags>
        <tag>谈心</tag>
      </tags>
  </entry>
  <entry>
    <title>我的一个道姑朋友-背景</title>
    <url>/2018/07/03/%E6%88%91%E7%9A%84%E4%B8%80%E4%B8%AA%E9%81%93%E5%A7%91%E6%9C%8B%E5%8F%8B-%E8%83%8C%E6%99%AF/</url>
    <content><![CDATA[<p>陌生人，你好。欢迎来到这里！</p>
<p>也许你也听过我的一个道姑朋友，感受也许很深，也许很浅。当然这并不重要，让我们一起来了解这首歌的背景，我相信，你看完后会有些感受。</p>
<iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width=330 height=86 src="//music.163.com/outchain/player?type=2&id=864027934&auto=1&height=66"></iframe>

<p>由于我找很长时间没找到以冬的链接，只能搜索播放器的链接奉上想听的朋友可以点击下：<a class="link"   href="https://music.957xx.cc/?name=%E6%88%91%E7%9A%84%E4%B8%80%E4%B8%AA%E9%81%93%E5%A7%91%E6%9C%8B%E5%8F%8B%20%20%E4%BB%A5%E4%B8%9C&type=qq" >点我<i class="fas fa-external-link-alt"></i></a></p>
<p><img  
                     lazyload
                     alt="image"
                     data-src="https://i.loli.net/2018/07/03/5b3b709216bc7.jpg"
                      alt="img"
                > </p>
<h5 id="女主："><a href="#女主：" class="headerlink" title="女主："></a>女主：</h5><p>​        我是个孤儿，那天我上山采药,突然下暴雨。不 知所措的我躲在屋檐下等雨停恍然看见一个 与我年龄相仿的少年。 他身着白衣撑着伞朝我走来，说要送我回家，而 我早已陷入他那对深邃的眼眸中心内一阵 悸动。他一把拉我入伞下。   我得知他是山上的道士，也刚好下山采药，他把  伞赠予我，一个人回去了。  还在茅屋门口目送他的我愣在原地。后来我采 药卖钱买了一盒桂花糕去山上和他道谢，他也很开心的样子收下了。我和他走在山路上像是孩子一样嬉戏，他送我   下山。之后我便总去给他送东西，不论是自己   做的还是买的，他也都会很开心的收下  ，之后我们聊着天。</p>
<p>​          每次他都送我下山，我们一 起骑着马一起游玩。 记得我送给他马具的时候他特别开心，他扶着在 我耳边说一直会保护我。 这天突然下暴雨，我住的茅屋破烂,于是决定去 山上当一个道姑，这样就能永远陪着他了。 </p>
<p>​         我带着他送给我的伞，还有为数不多的家产上 山去当了道姑，但他好像不在。另一个道长再三问我是不是确定好了要当道姑 ，当了道姑后要断红尘，即使这能永远陪在他身   边也好。 于是就换了一身素装，成了一名道姑，之后的日 子每天都能与他遇见，他还是原来的样子总是   和我嬉闹。   但我总是发现他老是下山而且越来越频繁，但   每次回来都会给我带来胭脂红妆什么的送给  我，我开心极了。    </p>
<p>​      这天夜晚，他刚从山下回来，敲我房门，要送给我一个胭脂,说这是最新款的，女孩子用了后特别漂亮，我开心极了。对他说，这样好像不太好,总是送我东西，被其他人看见就不好了，他说只管收着就好了。他问我，思念一个人是什么感觉，还没等我回答，他就转身离去了，我心里一阵悸动。就这样过了三年。</p>
<p>​       这天他突然说要还俗，因为他和乡下一个卖胭脂的姑娘私定了终身，并且答应要娶她,于是道长带着大家的祝福收拾收拾就下山了，我呆呆的愣在原地，眼眶渐渐湿润。原来三年前他喜欢的就不是我，那送我的那些胭脂只是为了讨好她，思念的人自然也不是我，想到这我泪水再也忍不住。不久就传来道长喜宴的消息，我假装偶然赶上他们的喜宴，他看见是我先是 愣了一下。</p>
<p><img  
                     lazyload
                     alt="image"
                     data-src="https://i.loli.net/2018/07/03/5b3b72626eaf1.jpg"
                      alt="img"
                > </p>
<p>​      他还是一身白衣如旧，依附在他身旁的佳人有如花的颜容。   她问他我是谁，他说是以前在山上当道士的   时候的   一个道姑朋友，身边佳人有露出了甜美的笑 容。此时不知为什么决定他们很是般配。但是   我还是想上前问他，是不是我送的马具不够好   看，是不是那天的桂花糕我没捂热，  是不是世上的人都是这样连自己的承诺都可 以随 意的收回。 好想一把上前抱住他在他白皙的侧脸留一个唇印，任旁人惊讶，可是我不能，只能强忍微笑给了 他们祝福,并把当年道长送我的伞送给了他们当作贺礼。 我在角落里独自饮酒，转身离去谁也没看见 我转身后的泪如雨下。</p>
<p>​      后来我一个人去了很多地方 从春天一直走到冬天，那个时候的那件事和事 里的那个人，就好像我做的一场梦。 现在梦醒了，什么都没了。    </p>
<h5 id="道士："><a href="#道士：" class="headerlink" title="道士："></a>道士：</h5><p>我是一个道士，却爱上了一个经常上山探药的 姑娘，她不知道我怕她发生危险经常在远处保护着她。 那天突下暴雨，见她却无带伞连忙寻伞去接她， 我一身白衣见她檐下避雨，一把拉入伞下， 我说送她回家。 姑娘面色绯红眼里闪着光，那是我这辈子见 到的最动人的眼神。我把伞赠予了她,独自一人回了山上。</p>
<p><img  
                     lazyload
                     alt="image"
                     data-src="https://i.loli.net/2018/07/03/5b3b729a5734c.jpg"
                      alt="img"
                > </p>
<p>后来她 到观中送来一盒桂花糕 与我道谢，以表感激我 送她下山，我和她走在山路上，她一直专心倾听   着我说的话。之后她总是会到观里来送我不同的东西，每次我都会收下后，和她一起聊天，送她下山。我们 一起骑马游玩,记得有一次她送我一具马鞍,我   那天很开心，把她拥入怀下伏在她耳边许道   ,我会一直保护她。  原本心中定了还俗的念想，  这天天下暴雨，我一个道友告知我，有位姑娘在   观中当了道姑，她一身素衣看见我后好像很开   心的样子，但我却心中忧郁万千，后来才知道她 是为了我才当了道姑。   还是，原来那样我们每天都有很多话聊为了讨   她欢心，我每次都会从山下挑一盒胭脂红妆回来送她，她也都会很开心的收下。 </p>
<p>​     这天晚上我挑了一个非常贵重的胭脂给她送了 过去她怕被人看见了不好，我说只管收着就好，问她，你知道思念是什么感觉么?她深思，我却   没等她回我便离开了去。   就这样过去了三年，一天我在山下胭脂摊挑选 胭脂，卖胭脂的是一位姑娘身着艳丽,却也没   过多注意。   不料下起暴雨，傍无伞具。姑娘见状便留我小   坐略饮薄茶等雨后天晴再走不迟。       </p>
<p>​      半饮过后，头感昏沉，心中情起。翌日早上，姑娘 |给我看榻上落红，并要我负责，虽尽是愧疚与悲 戚，但也不能推辞责任，免姑娘日后难见他人，那 天晚上我一人楼中独饮,心中她的身影若影若 现，不敢再去与她相见。 后来我还俗与姑娘大喜当天，她身红衣红唇， 美得凄凉，我却不敢正眼看她 身旁佳人问到她是谁，我只轻声回她一句那是我的一个道姑朋友。 </p>
<p>​     这天她一个人在角落不停地喝酒,最后也不知道她是怎么离开的。 傍晚,在满布红烛的房间里，佳人一人独坐红 榻。我抚摸着她送我的那具马鞍， 从袖中拿出那温热的桂花糕送入嘴中，眼中湿 润已久心里想的却不是眼前人。  </p>
<h5 id="胭脂姑娘："><a href="#胭脂姑娘：" class="headerlink" title="胭脂姑娘："></a>胭脂姑娘：</h5><p>​      我是个卖胭脂的姑娘，他是山上的道士我偷偷 留意他很久了。 在一个暴雨天我在我的摊位旁看到了他，为另 一个模样清秀的姑娘撑伞， 他们轻轻相拥，他说着好听的诺言说想一直拥 着她，那姑娘面色绯红，眼里闪着光一那是我这 辈子见到的最动人的眼神，但是我却嫉妒得发 狂,我一定要阻止他们在一起!  !不久后，听说那姑娘当了道姑，我有些不理解她 的想法。</p>
<p><img  
                     lazyload
                     alt="image"
                     data-src="https://i.loli.net/2018/07/03/5b3b72d488d36.jpg"
                      alt="img"
                > </p>
<p>​     但是,就在她当道姑那一天，我看到了 山下的他，我化着精致的妆容， 一颦一笑皆是风情，莲步轻移眉眼低垂，这是我有意为之的，我对自己的容颜有着十足的自信， 他却熟视无睹， 只是细细询问我各种胭脂的用法，后来他买了 几盒胭脂，脸_上漾着笑，他是在想她吧  </p>
<p>  不行，他是我爱的男人，我要用我的万种风情得   到他!他走后，我在铜镜前仔细端详自己的容颜，不知为何，却觉得 此刻的我的一双桃花眼竟比不上那个小   道姑的一对眸子..后来他常来我的店铺挑选胭   脂，但也只是选胭脂而已。   终于，有一天，他挑完胭脂后下起了雨，他没带伞，   我留他小坐略饮薄酒，并在他的酒中加了   催情，药，他浑然不觉…  </p>
<p>​     那个夜晚，我的阁中春色浓。翌日早上，我给他看榻上的落红，并要他负责，他的眼中尽是愧疚与悲戚，良久，他同意了。   大婚那日锣鼓喧天，好不热闹，我却看到了红唇   红衣的她，她明明只是中上之姿，比起我可差远   了,此刻我却觉得她有一种惊心动魄的美，我故   意在她面前问他这是谁，他怔了一刻随即平静   1地说道:”她是我的一个道姑朋友。”  </p>
<p>​      我乖巧地点了点头，拉他到一旁后来我看到她在角落里不停地饮酒 ，她是怎么离开的我也不得而知。傍晚,在布满 红烛的房间里，他并没有碰我，让我先睡我却在 深夜看到他抚摸着一副马 鞍,往嘴里塞着桂花 糕，压抑着自己的哭声。 房间的角落静静地躺着一把油纸伞.  </p>
<h5 id="婚礼上的一名宾客："><a href="#婚礼上的一名宾客：" class="headerlink" title="婚礼上的一名宾客："></a>婚礼上的一名宾客：</h5><p>​      我是婚礼上的一位宾客，至于叫什么就不便透 露了。卖胭脂的姑娘结婚了邀请我们这些邻 里去参加婚礼。 那个姑娘啊，我看着她从蹒跚学步到如今的豆 蔻年华，不知不觉居然要嫁人了。 外 面锣鼓喧天，屋里张灯结彩，好派喜庆的模 样。 可新郎生硬 的抱着新娘一脸落 寞看不 出一 丝的欢喜。</p>
<p>​    直到一位红衣道姑的出现才让他眼中焕发出惊 人的神采，我才觉得事情好像不是那么简单。 胭脂姑娘 问他那女子是谁，他愣了一下故作平 淡的说:“她是我的一个道姑朋友”。 多么平淡的一句话，可是我从里面听出了多么 复杂的情感一 不甘、愧疚、心灰意冷 于是我便留意起那位道姑朋友她看着淡然的 新郎红了眼眶，只是不停的饮酒.. 心里突然堵得慌。</p>
<p>​    我原来并不是一个多愁善感的人。是道长那一   瞬间仿佛活了过来的神采 ，还是道姑踉踉跄跄离去时眼角挂着的泪珠触   动了我?我不得而知，我只是觉得他们才是本应   该在起的人…  犹记那日天降大雨，我坐在门前屋檐下看见一   位道长撑伞雨中前行，白衣淡然,翩若惊鸿。   他把一位姑娘拥入怀中脸上溢着淡淡的笑容，   或许才这是抱住了幸福的模样吧..  </p>
<h5 id="结局："><a href="#结局：" class="headerlink" title="结局："></a>结局：</h5><p>  道士走后，留下胭脂姑娘，没人知道道姑走到哪里，道士只想一直找 下去他相信总有一天会找到她…道姑走过海边，这是她第一次见到海，可她想与心中的那人一起倾听大海的声音想到这,她自嘲的笑笑，几天后路过这里，一位白衣少年驾着马,他心想:她一定会喜欢大海。</p>
<p>​     可少年没有停下，他不敢停下，害怕再次错过 她。道姑来到瀑布下，站在一块石头 上感受 到冰凉的水珠轻吻着她的脸颊她不禁想起那年道士大婚时她很想走_上去 把抱住他,在他白 净的脸留一 个唇印。怎么又想起这件事，道姑自言自语道。 几天后，白衣少年依旧马不停蹄地赶着。 连风景都来不及看。 </p>
<p>​    五年过去了，少年陪道姑看完了这世间的繁华 和苍凉。 他们近在咫尺却远在天变道姑来到了洛阳，正 值夏季，突然来的暴雨让道姑不知所措，慌乱中 她跌入了一个温暖的怀抱，她吓得-愣， 抬眼一看，一张陌生的脸她有些失望眼底闪 过一抹不经意间的落寞， 1但她很快反应过来的对那个人道歉.  </p>
<p>   她想着:他应该已经和那位姑娘都有了孩子吧， 怎会来寻我。 水从她脸_上划过，不知是泪水还是雨水。 这时，一双好看的手将她拉入怀中道士在她耳 边轻声说到“我找了你五年,还俗吧，我娶你。</p>
<p><img  
                     lazyload
                     alt="image"
                     data-src="https://i.loli.net/2018/07/03/5b3b733e2bed9.jpg"
                      alt="img"
                > </p>
<h5 id="感谢总结："><a href="#感谢总结：" class="headerlink" title="感谢总结："></a>感谢总结：</h5><p> 首先给看完的棒棒的你一个掌声，由于文章的字数较多。可能分段本人分的也不太好，也感谢你，陌生人！能看完这篇文章。 也许我们的人生就是一段旅行，一声会看见很多人可是真正有感觉的人总是那么一两个。走到一起真的不容易，珍惜眼前情义。</p>
]]></content>
      <tags>
        <tag>谈心</tag>
      </tags>
  </entry>
  <entry>
    <title>来聊(水)下最近hexo备份的思路</title>
    <url>/2022/11/11/%E6%9D%A5%E8%81%8A-%E6%B0%B4-%E4%B8%8B%E6%9C%80%E8%BF%91hexo%E5%A4%87%E4%BB%BD%E7%9A%84%E6%80%9D%E8%B7%AF/</url>
    <content><![CDATA[<h1 id="出现问题"><a href="#出现问题" class="headerlink" title="出现问题"></a>出现问题</h1><p>最近（2020-2022）博客出现了短暂的停更状态。</p>
<p>具体原因是因为hexo的文章文件夹在编译过后并不会存储在GitHub的仓库里，而我也同样因为电脑硬盘损坏而失去了我的博客维护权限。</p>
<p>朋友们也在这期间纷纷到访过博客，尤其是更换友联站点的url、更新文章中的错别字这种<strong>强需求</strong>无法及时的得到支持。</p>
<h1 id="解决思路"><a href="#解决思路" class="headerlink" title="解决思路"></a>解决思路</h1><ol>
<li>把hexo文件夹备份至自己的本地的文件</li>
<li>把hexo整个文件夹备份至git，并且手动add、commit等</li>
<li>采用同步盘的思想，hexo文件夹放入同步盘文件夹中。搬设备到各个平台只需要登陆账户即可</li>
</ol>
<p>重点说一下同步盘的思想</p>
<p>无论是定期备份、还是每次写完文章后都把自己的文件夹手动的add、commit至git仓库，似乎都不是那么的解放双手？写完忘同步，忘commit都会产生数据丢失的问题。</p>
<p>然而采用同步盘既可以解决备份，还可以解决以下问题：</p>
<ol>
<li>多设备编辑文章，在iPhone、Android、Mac、Windows、Pad端都可以做到编辑markdown文件，实现写作自由。有网络的地方就有hexo，就有认真写博客的倔强青年！</li>
<li>好的同步盘甚至具有协作的功能，这里幻想一下，博客也能跟小伙伴一起协作的快感。</li>
</ol>
<p>无论如何怎么看，似乎同步盘都可以解决更多的问题。</p>
<h1 id="同步盘的选型"><a href="#同步盘的选型" class="headerlink" title="同步盘的选型"></a>同步盘的选型</h1><p>同步盘的产品众多，大厂小厂甚至网盘行业都会来抢这块蛋糕，那我们就从以下几个方面选型市面上产品</p>
<ol>
<li>跨平台性，针对多设备的兼容</li>
<li>不限速</li>
<li>bugfix的数量以及修复的速度</li>
<li>易用性</li>
</ol>
<p>简单的来说，入围的产品有<strong>OneDrive、iCloud、DropBox、坚果云</strong>。</p>
<h1 id="说搞就搞"><a href="#说搞就搞" class="headerlink" title="说搞就搞"></a>说搞就搞</h1><ol>
<li>拷贝文件夹到oneDrive</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cp hexo /Users/zhangshuaike/OneDrive/hexo/</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>等待同步就好，同步完成后在别的设备下载OneDrive，打开hexo文件夹管理即可</li>
</ol>
<h1 id="待解决的问题"><a href="#待解决的问题" class="headerlink" title="待解决的问题"></a>待解决的问题</h1><ul>
<li>如果换了新的设备，怎么初始化npm相关包？好说，搞个<strong>init.sh</strong>即可</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">echo &#x27;hexo 52xk.cc start&#x27;</span><br><span class="line">cd 52xk.cc</span><br><span class="line">npm install -g hexo-cli</span><br><span class="line">echo &#x27;hexo init success&#x27;</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">npm install hexo-theme-keep</span></span><br><span class="line">echo &#x27;hexo init theme:keep,success&#x27;</span><br><span class="line">npm install hexo-generator-searchdb</span><br><span class="line">echo &#x27;search 插件安装成功&#x27;</span><br><span class="line">echo &#x27;deploy插件&#x27;</span><br><span class="line">npm install hexo-deployer-git --save</span><br><span class="line">echo &#x27;start localhost:4000&#x27;</span><br><span class="line">hexo s</span><br></pre></td></tr></table></figure>

<p>采用同步盘，非常方便稳定的就解决了hexo的数据丢失无法维护的问题。大家可以试一试</p>
]]></content>
      <tags>
        <tag>hexo</tag>
        <tag>OneDrive</tag>
      </tags>
  </entry>
  <entry>
    <title>老朋友，别来无恙啊。</title>
    <url>/2018/06/28/%E6%AC%A2%E8%BF%8E%E6%9D%A5%E5%88%B0%E5%B0%8F%E8%BD%B2%E5%8D%9A%E5%AE%A2/</url>
    <content><![CDATA[<h1 id="Hi，My-Friend-，Hello-hexo"><a href="#Hi，My-Friend-，Hello-hexo" class="headerlink" title="Hi，My Friend ，Hello hexo"></a>Hi，My Friend ，Hello hexo</h1><p>朋友，你好啊~  别来无恙啊。</p>
<p>没错，你又看到了，我好像又折腾了一波。</p>
<p>估计这次完事之后不会在折腾了，等着穷到毕业~</p>
<p>但是这个博客也是挺好的，做的其中遇到了很多的问题，也特别感谢我的表哥<a class="link"   href="https://qsong.top/" >@唯美陌阡<i class="fas fa-external-link-alt"></i></a>,因为从来没想过这么多问题。也是做起来比动态博客还要麻烦的一批~帮助我解决了很多问题。</p>
<p>反正最后磕磕绊绊的还是过来了~  </p>
<hr>
<h1 id="为何要搬过来？"><a href="#为何要搬过来？" class="headerlink" title="为何要搬过来？"></a>为何要搬过来？</h1><p>做一个动态博客的成本确实不小，在我这个小小的学生狗面前还是付不起那种高级的服务器费用，同时这个没有那么多限制，可以随心所欲。恩 还得继续 加油！</p>
]]></content>
      <tags>
        <tag>hexo</tag>
        <tag>hello</tag>
      </tags>
  </entry>
  <entry>
    <title>那些年我们在北京租过的房子</title>
    <url>/2018/07/13/%E9%82%A3%E4%BA%9B%E5%B9%B4%E6%88%91%E4%BB%AC%E5%9C%A8%E5%8C%97%E4%BA%AC%E7%A7%9F%E8%BF%87%E7%9A%84%E6%88%BF%E5%AD%90/</url>
    <content><![CDATA[<p>2006年，因为转学到北京，我开始在学校门口租房。我人生第一次自己租住的房子，是学校附近不远的城中村。城中村的入口在清华旁边的一条宽广的马路上，门口看只是一条普通的巷子。走进去1000米，才会看到里面别有洞天。这个城中村全部都是平房以及农民自己搭建的小二楼，住着的都是附近卖菜的送水的或者做小生意的一些社会最底层的劳动人民。我住的房间大约有40平米，平房，一月500块，和三个女生一起合住，每人的租金不到200块钱。没有厕所和厨房，都要去公用的厕所，有时候你在坑上蹲着，面前就飘来一只大狼狗。这里什么都有卖，打电话都便宜的很，瓜果梨桃卖的也很便宜。我在这里住了大约一两个月，因此治安不好，天天有房间被盗，而我跟同屋的女生也不太处的来。他们要早起早睡，而我还是学生要做功课。几次矛盾下来，我就离开了。我再也没有回去过，但是每次看到电视里南方工厂里打工妹生活的纪录片，我就会想起那个地方来，总觉得，那是特别珍贵的一段经历和记忆。</p>
<p> <img  
                     lazyload
                     alt="image"
                     data-src="https://i.loli.net/2019/07/02/5d1b259a7712389665.jpg"
                      alt="img"
                > </p>
<p>后来我搬家到学校门口一个房子里的床位，一个三居室，住着14个人，我的小房间有四个女生，另外一个大房间有八个男生，还有一对小情侣在小屋里住着，每人300元每月。我在这里住了大约两年，舍友换了无数无数，中国的外国的，打工的考研的，精神正常的精神不正常的。有个姐姐的老公在对面的学校里读博士，她在门口租一个床位陪读，后来他们毕业后一起去了美国。有个女生在那个屋子里考了三年北大光华MBA，终于梦想成真，考上的那一年她哭的坐不起来。有人在那个屋子里恋爱又失恋，有人在那个屋子里每天摔摔打打。每天晚上排队洗澡洗衣服像一个风景，着急的时候头冲着水龙头随便洗一下就湿漉漉的去上课了。那时候似乎谁都没有想起来还有吹风机，也不觉得人多。14个人一起在客厅看电视的时候，拥挤的场面简直像世界杯直播一样热闹。</p>
<p>大学最后一学期，我因为实习在CBD区，天天上班要2个小时实在要吐血了，于是在北京大望路地铁站旁边与人合租了一间房。这间房子总共6平米，一人一张床占4平米，还有半平米放衣柜，1.5平米的地面。这间房子价格800元，我和另一个女生一人400元，那时候实习工资是每月1200，后来变成1760。我们两个都是一个行业，因此相处还比较容易。我实习时候经常加班到深夜，每次回来的时候，她已经睡了，只有灯亮着电脑开着收音机在被子里也开着。每次回家都要翻开她被子找收音机关掉，再关灯关电脑。她的电脑是台式机，总是轰轰的声音，我叫她的电脑是拖拉机。我们一起住了半年，彼此毕业开始正式工作，但低廉的工资让我们依旧只能还住在这个楼里，因为这里是还算黄金位置的大望路地铁边上唯一的年代久远的筒子楼，价格比同小区的高层住宅要便宜很多。</p>
<p><img  
                     lazyload
                     alt="image"
                     data-src="https://i.loli.net/2019/07/02/5d1b25b740c3f73843.jpg"
                      alt="img"
                > </p>
<p>她换到另外一个20平米的大房间里与人合租，我继续一人租这个小房间租了半年。这期间，我很好的大学朋友去了法国读MBA，临走和我坐在小房子里聊天，房子太小了，我有点不好意思让她来。我妈来北京看奥运会也住在这里，因为太热没有空调，我妈睡在地上，我睡在床上。我妈后来说，看见我住的这么小，心里很难受。这期间我还买了我第一个笔记本，是一个二手的笔记本，1200元钱，我就是用这个笔记本开始了我的写作道路，一直到三年后这个本光荣就义。</p>
<p><img  
                     lazyload
                     alt="image"
                     data-src="https://i.loli.net/2019/07/02/5d1b25ce8c1c275032.jpg"
                      alt="img"
                >  </p>
<p>再过半年，隔壁的姑娘要换房子，我就去了隔壁20平米的大房间，每月1000元，水电网另计，怎么也要每月1200吧。网络我从一楼的一户人家牵线上来，上来后还分给三家用，因此每月大约20块钱就够了。到现在每次交很贵的网费的时候总是想起这事儿，还总想总隔壁分一根线，可惜没人跟我分了。要说这个房子大而光明，还挺不错的，但唯一的问题是厕所。因为四家合用，隔壁是三个男生，一对夫妻，门口那家是八个洗脚妹，人多到厕所巨堵，到后期天天屎飘在马桶里，你还不得不继续上。更惨烈的是有时候你在旁边洗澡，旁边就是飘着屎的马桶。找人来通了很多很多次，但终究不知道为什么还总是要赌。门口的打工妹用洗衣机总是把水流到楼道里，楼上和楼下的邻居就会来破口大骂，好几次打110报警，每次我都要连哄带骗的安慰邻居，再收拾楼道，因为洗脚妹们开着洗衣机就不知道去哪儿玩儿去了。在这个房子里，我开始每天1500字写博客，雷打不动的坚持，就是从这个房子里开始的。开始用电饭锅给自己做饭，买了一个二手洗衣机200块钱，都是从这里开始。</p>
<p><img  
                     lazyload
                     alt="image"
                     data-src="https://i.loli.net/2019/07/02/5d1b25b740c3f73843.jpg"
                      alt="img"
                >  </p>
<p>房子到期后，我决定离开这个屎太多的地方。于是在网上找到了蒲黄榆的一个房子。这是个大约有20年历史的老房子，是个高层，还是个银行的宿舍，因此邻居都是老人家，且鲜有租客。房子陈旧，但能看得出当年是新房的时候，房东还是花了大力气装成当年最时髦的样子，家具虽然过时，都都是上好的实打实的实木家具。在这里，我结交了非常好的朋友。他们知道我是个半夜写作白天上班的人，因此主动承担起三年倒垃圾打扫卫生的工作，从来不用我动手，也不用操心。可能我做饭比较烂，他们每次都做好饭给我送来吃，从来不让我进厨房，还说我进厨房一次她们要收拾半宿还是她们来吧。起初我在这里租住最小的房间6平米，600元，小小的热热的但很温馨，我就在这个小房间里写了我人生的第一本书《从北京到台湾这么近那么远》。那时候记者来我家采访，三个人根本站不进来，只能我和记者坐在床上，摄影大哥站门口，还一位站走廊里。现在每次看到这本书，都忍不住想到那些小日子，只有梦想，能让人克服一切的困难，让每天的日子，都闪闪发亮！</p>
<p> <img  
                     lazyload
                     alt="image"
                     data-src="https://i.loli.net/2019/07/02/5d1b26516fc3c82430.jpg"
                      alt="img"
                > </p>
<p>后来我转到隔壁20平米1000元每月的房间里，到我走的时候房间的价格差不多1500一个月，因为是房东直租，依旧算是很便宜的价格吧。只是唯一重大的问题是，这个房间楼下正对着一个神经衰弱还有心脏病的老太太，只要我在楼上小心翼翼的走一步路，老太太都会认为是之天大的声音而找上门来，甚至为此心脏病发急救过。后来，房东把新买的地毯都放在了我的房间里，老太太依然能听到声音，甚至半夜一点把110叫来投诉我扰民，可是110来了看见什么都没有随便打发下就走了。无力承受老太太的生命，只能三五天去一趟老太太家，提着瓜果梨桃去看看她是在家好好的还是又去医院了。在这个房间里， 我写了我人生第三本书，并跳了槽，度过了两年半的时光，我毕业后重要的人生转变，职场转变，以及迅速的成熟长大都是在这里，包括遇到至好的朋友，以及终于过上了安全而安稳的生活。</p>
<p>后来，因为租房的价格愈发昂贵，我买了房子；再后来我结婚，又换到了婚房里。尽管自己的房子干净又整洁，安静又安稳，但我总记得那些租房子的时光，那些铭刻在我青春里的每一天，那些心惊胆战又脏乱差的日子，或者被110训话或被邻居投诉的日子，像利剑挂在我心上，又像星星，回想起来会给自己点赞。直到现在，我依旧喜欢帮朋友找房子，喜欢没事儿看租房网站，总会回想起以前自己租房的日子，以及那些在下班后黑灯瞎火与中介去黑漆漆的小区看房子的场景。</p>
<p>我一直相信，有一天每一个人都会有自己的房子，自己的家庭。这大千世界的一隅，总有一天会有一盏等着我们回家的灯。而年轻的时候所有的颠沛流离都将成为日后心中的慰藉，是青春的圣火，是跃动的生命。它们闪着光，透着亮，提醒着我们曾经那么年轻，曾经那么敢闯，曾经天不怕地不怕，曾经什么都可以接受和忍耐。</p>
<p>所有的年轻，有一天都会长大与成熟，当回忆往事的时候，望着远方，怦然一笑，就是对青春时光里所有的所有，最好的诠释与珍藏。</p>
]]></content>
      <tags>
        <tag>鸡汤</tag>
      </tags>
  </entry>
</search>
